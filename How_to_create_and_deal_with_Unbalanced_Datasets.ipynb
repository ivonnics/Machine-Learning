{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "How to create and deal with Unbalanced Datasets.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPrbJKgObPemxqgjVmwJcbE",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ivonnics/Machine-Learning/blob/master/How_to_create_and_deal_with_Unbalanced_Datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2UMk4cEPzFr",
        "colab_type": "text"
      },
      "source": [
        "## Taken from: https://machinelearningmastery.com/imbalanced-classification-is-hard/\n",
        "\n",
        "## Muy buenos: https://medium.com/strands-tech-corner/unbalanced-datasets-what-to-do-144e0552d9cd & https://elitedatascience.com/imbalanced-classes\n",
        "\n",
        "https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/\n",
        "\n",
        "https://www.kdnuggets.com/2017/06/7-techniques-handle-imbalanced-data.html\n",
        "\n",
        "https://towardsdatascience.com/handling-imbalanced-datasets-in-machine-learning-7a0e84220f28\n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2017/03/imbalanced-data-classification/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-G_7FncpPbDp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# vary the dataset size for a 1:100 imbalanced dataset\n",
        "from collections import Counter\n",
        "from sklearn.datasets import make_classification\n",
        "from matplotlib import pyplot\n",
        "from numpy import where\n",
        "# dataset sizes\n",
        "sizes = [100, 1000, 10000, 100000]\n",
        "# create and plot a dataset with each size\n",
        "for i in range(len(sizes)):\n",
        "\t# determine the dataset size\n",
        "\tn = sizes[i]\n",
        "\t# create the dataset\n",
        "\tX, y = make_classification(n_samples=n, n_features=2, n_redundant=0,\n",
        "\t\tn_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)\n",
        "\t# summarize class distribution\n",
        "\tcounter = Counter(y)\n",
        "\tprint('Size=%d, Ratio=%s' % (n, counter))\n",
        "\t# define subplot\n",
        "\tpyplot.subplot(2, 2, 1+i)\n",
        "\tpyplot.title('n=%d' % n)\n",
        "\tpyplot.xticks([])\n",
        "\tpyplot.yticks([])\n",
        "\t# scatter plot of examples by class label\n",
        "\tfor label, _ in counter.items():\n",
        "\t\trow_ix = where(y == label)[0]\n",
        "\t\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n",
        "\tpyplot.legend()\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vG2G10doSc9w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pip install -U imbalanced-learn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAzrz-77FAgm",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cRPLRRQSxGW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://imbalanced-learn.readthedocs.io/en/stable/api.html\n",
        "# https://imbalanced-learn.readthedocs.io/en/stable/auto_examples/index.html\n",
        "import pandas as pd\n",
        "import imblearn.under_sampling as under\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "breast_cancer = load_breast_cancer()\n",
        "pd.Series(breast_cancer.target).value_counts()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh30Au4UmfKM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "UnderSampling = under.ClusterCentroids(sampling_strategy={1:300, 0:212}, random_state=83, voting='hard')\n",
        "x_resampled, y_resampled = UnderSampling.fit_resample(breast_cancer.data, breast_cancer.target)\n",
        "pd.Series(y_resampled).value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7RrgTg5pD2t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# https://stackoverflow.com/questions/38105539/how-to-convert-a-scikit-learn-dataset-to-a-pandas-dataset/46379878#46379878\n",
        "# https://stackoverflow.com/questions/48769682/how-do-i-convert-data-from-a-scikit-learn-bunch-object-to-a-pandas-dataframe\n",
        "\n",
        "def answer_one(): \n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.datasets import load_breast_cancer \n",
        "    cancer = load_breast_cancer()     \n",
        "    data = np.c_[cancer.data, cancer.target]\n",
        "    columns = np.append(cancer.feature_names, [\"target\"])\n",
        "    return pd.DataFrame(data, columns=columns)\n",
        "\n",
        "answer_one()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H821OO8t8bmU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# From: https://elitedatascience.com/imbalanced-classes\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        " \n",
        "# Read dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/ivonnics/Machine-Learning/master/DATA/balance-scale.data', \n",
        "                 names=['balance', 'var1', 'var2', 'var3', 'var4'])\n",
        " \n",
        "# Display example observations\n",
        "print(df.info())\n",
        "df"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWXoT7749G8h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(df['balance'].value_counts())\n",
        "print(df['var1'].value_counts())\n",
        "print(df['var2'].value_counts())\n",
        "print(df['var3'].value_counts())\n",
        "print(df['var4'].value_counts())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwUjg7uF9j0I",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df['balance'] = [1 if b=='B' else 0 for b in df.balance]\n",
        "df['balance'].value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oEEUFQn30sdF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(df)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufGojzJatwP5",
        "colab_type": "text"
      },
      "source": [
        "## The Danger of Imbalanced Classes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpDpcF0_-_Nk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2rWG-AM_CuQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Separate input features (X) and target variable (y)\n",
        "y = df.balance\n",
        "X = df.drop('balance', axis=1)\n",
        " \n",
        "# Train model\n",
        "clf_0 = LogisticRegression().fit(X, y)\n",
        " \n",
        "# Predict on training set\n",
        "pred_y_0 = clf_0.predict(X)\n",
        "# How's the accuracy?\n",
        "print( accuracy_score(pred_y_0, y) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciMQ5bkz_Zi-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Should we be excited?\n",
        "print( np.unique( pred_y_0 ) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FehKJm3_6G9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import resample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCM3awkoAA68",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Separate majority and minority classes\n",
        "print('DF Majority:')\n",
        "df_majority = df[df.balance==0]\n",
        "print(df_majority)\n",
        "print(df_majority.info())\n",
        "print('__________________________________________________________')\n",
        "print('DF Minority:')\n",
        "df_minority = df[df.balance==1]\n",
        "print(df_minority)\n",
        "print(df_minority.info())\n",
        "print('__________________________________________________________')\n",
        "print('DF Minority UNSAMPLED:')\n",
        "# Upsample minority class\n",
        "# sample with replacement to match majority class reproducible results\n",
        "df_minority_upsampled = resample(df_minority, replace=True, n_samples=len(df_majority), random_state=123) \n",
        "print(df_minority_upsampled)\n",
        "print(df_minority_upsampled.info())\n",
        "print('__________________________________________________________')\n",
        "print('DF UNSAMPLED:')\n",
        "# Combine majority class with upsampled minority class\n",
        "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
        "print(df_upsampled)\n",
        "print(df_upsampled.info())\n",
        "print('__________________________________________________________')\n",
        " \n",
        "# Display new class counts\n",
        "df_upsampled.balance.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPDJboG5AGfr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Separate input features (X) and target variable (y)\n",
        "y = df_upsampled.balance\n",
        "print(y)\n",
        "X = df_upsampled.drop('balance', axis=1)\n",
        "print(X)\n",
        " \n",
        "# Train model\n",
        "clf_1 = LogisticRegression().fit(X, y)\n",
        " \n",
        "# Predict on training set\n",
        "pred_y_1 = clf_1.predict(X)\n",
        " \n",
        "# Is our model still predicting just one class?\n",
        "print( np.unique( pred_y_1 ) )\n",
        "# [0 1]\n",
        " \n",
        "# How's our accuracy?\n",
        "print( accuracy_score(y, pred_y_1) )\n",
        "# 0.513888888889"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxZrhKH-AOap",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Separate majority and minority classes\n",
        "df_majority = df[df.balance==0]\n",
        "df_minority = df[df.balance==1]\n",
        " \n",
        "# Downsample majority class\n",
        "df_majority_downsampled = resample(df_majority, \n",
        "                                 replace=False,    # sample without replacement\n",
        "                                 n_samples=len(df_minority),     # to match minority class\n",
        "                                 random_state=123) # reproducible results\n",
        "\n",
        "print(df_majority_downsampled)\n",
        "print(df_majority_downsampled.info())\n",
        "print('______________________________________________________________')\n",
        "# Combine minority class with downsampled majority class\n",
        "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
        "print(df_downsampled)\n",
        "print(df_downsampled.info())\n",
        "print('______________________________________________________________')\n",
        "# Display new class counts\n",
        "df_downsampled.balance.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boNeLM1sATgE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Separate input features (X) and target variable (y)\n",
        "y = df_downsampled.balance\n",
        "X = df_downsampled.drop('balance', axis=1)\n",
        " \n",
        "# Train model\n",
        "clf_2 = LogisticRegression().fit(X, y)\n",
        "print(clf_2)\n",
        "print('__________________________________________')\n",
        " \n",
        "# Predict on training set\n",
        "pred_y_2 = clf_2.predict(X)\n",
        " \n",
        "# Is our model still predicting just one class?\n",
        "print( np.unique( pred_y_2 ) )\n",
        "# [0 1]\n",
        " \n",
        "# How's our accuracy?\n",
        "print( accuracy_score(y, pred_y_2) )\n",
        "# 0.581632653061"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOujHr7cCgCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIoafL9gCklU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Predict class probabilities\n",
        "prob_y_2 = clf_2.predict_proba(X)\n",
        "print(prob_y_2)\n",
        "print('______________________________________________________________')\n",
        " \n",
        "# Keep only the positive class\n",
        "prob_y_2 = [p[1] for p in prob_y_2]\n",
        " \n",
        "prob_y_2[:5] # Example\n",
        "# [0.45419197226479618,\n",
        "#  0.48205962213283882,\n",
        "#  0.46862327066392456,\n",
        "#  0.47868378832689096,\n",
        "#  0.58143856820159667]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liCH3GQkDkK5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print( roc_auc_score(y, prob_y_2) )\n",
        "# 0.568096626406"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xDgxGj3Dpxu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prob_y_0 = clf_0.predict_proba(X)\n",
        "prob_y_0 = [p[1] for p in prob_y_0]\n",
        " \n",
        "print( roc_auc_score(y, prob_y_0) )\n",
        "# 0.530718537415"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Svt2rLfVDygB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\tfrom sklearn.svm import SVC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdceHRxVD5ZU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Separate input features (X) and target variable (y)\n",
        "y = df.balance\n",
        "X = df.drop('balance', axis=1)\n",
        " \n",
        "# Train model\n",
        "clf_3 = SVC(kernel='linear', \n",
        "            class_weight='balanced', # penalize\n",
        "            probability=True)\n",
        " \n",
        "clf_3.fit(X, y)\n",
        " \n",
        "# Predict on training set\n",
        "pred_y_3 = clf_3.predict(X)\n",
        " \n",
        "# Is our model still predicting just one class?\n",
        "print( np.unique( pred_y_3 ) )\n",
        "# [0 1]\n",
        " \n",
        "# How's our accuracy?\n",
        "print( accuracy_score(y, pred_y_3) )\n",
        "# 0.688\n",
        " \n",
        "# What about AUROC?\n",
        "prob_y_3 = clf_3.predict_proba(X)\n",
        "prob_y_3 = [p[1] for p in prob_y_3]\n",
        "print( roc_auc_score(y, prob_y_3) )\n",
        "# 0.5305236678"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU_5rPw0EBlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QEhgAGgEGx9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Separate input features (X) and target variable (y)\n",
        "y = df.balance\n",
        "X = df.drop('balance', axis=1)\n",
        " \n",
        "# Train model\n",
        "clf_4 = RandomForestClassifier()\n",
        "clf_4.fit(X, y)\n",
        " \n",
        "# Predict on training set\n",
        "pred_y_4 = clf_4.predict(X)\n",
        " \n",
        "# Is our model still predicting just one class?\n",
        "print( np.unique( pred_y_4 ) )\n",
        "# [0 1]\n",
        " \n",
        "# How's our accuracy?\n",
        "print( accuracy_score(y, pred_y_4) )\n",
        "# 0.9744\n",
        " \n",
        "# What about AUROC?\n",
        "prob_y_4 = clf_4.predict_proba(X)\n",
        "prob_y_4 = [p[1] for p in prob_y_4]\n",
        "print( roc_auc_score(y, prob_y_4) )\n",
        "# 0.999078798186"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}