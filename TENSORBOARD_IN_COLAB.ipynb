{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TENSORBOARD IN COLAB.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ivonnics/Machine-Learning/blob/master/TENSORBOARD_IN_COLAB.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N0NASvKr9jXi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install tensorboardcolab"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgLjOkvuBxS7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorboardcolab as tb\n",
        "tbc = tb.TensorBoardColab()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhQuH9zG2k1r",
        "colab_type": "text"
      },
      "source": [
        "# You have to save all your logs in ./Graph\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8OpUIuogaiZI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# This is by far, the best example of what Tensorflow can display:\n",
        "# Scalars\n",
        "# Graphs\n",
        "# Distributions and...\n",
        "# Histograms\n",
        "# Tienes que guardar tus logs en ./Graph\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "W = tf.Variable([.3], tf.float32, name=\"W\")\n",
        "b = tf.Variable([-.3], tf.float32, name = \"b\")\n",
        "x = tf.placeholder(tf.float32, name=\"x\")\n",
        "with tf.name_scope(\"linear_model\"):\n",
        "    linear_model = W * x + b\n",
        "\n",
        "    # Tensorboard Histogram Summary of W and b\n",
        "    tf.summary.histogram(\"W\", W)\n",
        "    tf.summary.histogram(\"b\", b)\n",
        "\n",
        "y = tf.placeholder(tf.float32, name=\"y\")\n",
        "with tf.name_scope(\"loss_computation\"):\n",
        "    loss = tf.reduce_sum(tf.square(linear_model - y))\n",
        "\n",
        "    # Tensorboard Scalar Summaries for Loss\n",
        "    tf.summary.scalar(\"loss\", loss)\n",
        "\n",
        "optimizer = tf.train.GradientDescentOptimizer(0.01)\n",
        "train = optimizer.minimize(loss)\n",
        "x_train = [1,2,3,4]\n",
        "y_train = [0,-1,-2,-3]\n",
        "init = tf.global_variables_initializer()\n",
        "\n",
        "# Merge Summaries\n",
        "merged_summary = tf.summary.merge_all()\n",
        "\n",
        "sess = tf.Session()\n",
        "sess.run(init)\n",
        "\n",
        "# Graph Summary\n",
        "writer = tf.summary.FileWriter(\"./Graph\")\n",
        "writer.add_graph(sess.graph)\n",
        "\n",
        "for i in range(1000):\n",
        "  train_result, summary_result = sess.run([train,merged_summary], {x:x_train, y:y_train})\n",
        "  writer.add_summary(summary_result, i)\n",
        "\n",
        "curr_W, curr_b, curr_loss  = sess.run([W, b, loss], {x:x_train, y:y_train})\n",
        "print(\"W: %s b: %s loss: %s\"%(curr_W, curr_b, curr_loss))\n",
        "\n",
        "# W: [-0.9999969] b: [ 0.99999082] loss: 5.69997e-11"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UUXLjCGoIi6Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "a = tf.constant(1.0, name='a')\n",
        "b = tf.constant(2.0, name='b')\n",
        "c = tf.constant(3.0, name='c')\n",
        "d = tf.constant(4.0, name='d')\n",
        "e = tf.constant(5.0, name='e')\n",
        "f = ((a - b + c) * d )/e\n",
        "\n",
        "sess = tf.Session()\n",
        "writer = tf.summary.FileWriter(\"./Graph\")\n",
        "writer.add_graph(sess.graph)\n",
        "\n",
        "print (\"Expected: ((1 - 2 + 3) * 4)/5.0 = \", ((1 - 2 + 3) * 4)/5.0)\n",
        "result = sess.run(f)\n",
        "print( \"Via Tensorflow: ((1 - 2 + 3) * 4)/5.0 = \", result)\n",
        "\n",
        "# Expected: ((1 - 2 + 3) * 4)/5.0 =  1.6\n",
        "# Via Tensorflow: ((1 - 2 + 3) * 4)/5.0 =  1.6"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2ygr7qjbznA3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "a = tf.placeholder(tf.float32, name='a')\n",
        "b = tf.placeholder(tf.float32, name='b')\n",
        "c = tf.placeholder(tf.float32, name='c')\n",
        "d = tf.placeholder(tf.float32, name='d')\n",
        "e = tf.placeholder(tf.float32, name='e')\n",
        "f = ((a - b + c) * d )/e\n",
        "\n",
        "sess = tf.Session()\n",
        "writer = tf.summary.FileWriter(\"./Graph\")\n",
        "writer.add_graph(sess.graph)\n",
        "\n",
        "print (\"Expected: ((1 - 2 + 3) * 4)/5.0 = \", ((1 - 2 + 3) * 4)/5.0)\n",
        "result = sess.run(f,feed_dict={a:1,b:2,c:3,d:4,e:5})\n",
        "print (\"Via Tensorflow: ((1 - 2 + 3) * 4)/5.0 = \", result)\n",
        "\n",
        "# Expected: ((1 - 2 + 3) * 4)/5.0 =  1.6\n",
        "# Via Tensorflow: ((1 - 2 + 3) * 4)/5.0 =  1.6\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ppG_qyibMFWh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "a_data = np.array([[1,1],[1,1]])\n",
        "b_data = np.array([[2,2],[2,2]])\n",
        "c_data = np.array([[5,5],[5,5]])\n",
        "d_data = np.array([[3,3],[3,3]])\n",
        "\n",
        "a = tf.constant([[1.0,1.0],[1.0,1.0]], name='a')\n",
        "b = tf.constant([[2.0,2.0],[2.0,2.0]], name='b')\n",
        "c = tf.Variable(initial_value=[[5.0,5.0],[5.0,5.0]], name='c')\n",
        "d = tf.placeholder(tf.float32, name='d')\n",
        "e = (a + b - c) * d\n",
        "\n",
        "sess = tf.Session()\n",
        "writer = tf.summary.FileWriter(\"./Graph\")\n",
        "writer.add_graph(sess.graph)\n",
        "\n",
        "print (\"Expected:\", (a_data + b_data - c_data) * d_data)\n",
        "sess.run(tf.global_variables_initializer())\n",
        "result = sess.run(e,feed_dict={d:[[3.0,3.0],[3.0,3.0]]})\n",
        "print( \"Via Tensorflow: \", result)\n",
        "\n",
        "# Expected: [[-6 -6]\n",
        "#  [-6 -6]]\n",
        "# Via Tensorflow:  [[-6 -6]\n",
        "#  [-6 -6]]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sdy45nI1LSw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Generate Random Data\n",
        "examples = 1000\n",
        "features = 100\n",
        "x_data = np.random.randn(examples, features)\n",
        "y_data = np.random.randn(examples,1)\n",
        "\n",
        "# Define the Linear Regression Model\n",
        "X = tf.placeholder(tf.float32, shape=[None, features], name = \"X\")\n",
        "y = tf.placeholder(tf.float32, shape=[None, 1], name = \"y\")\n",
        "w = tf.Variable(tf.random_normal(shape=[features,1]), name= \"w\")\n",
        "b = tf.Variable(tf.random_normal(shape=[1,1]), name=\"b\")\n",
        "y_hat = tf.add(tf.matmul(X,w),b, name=\"y_hat\")\n",
        "\n",
        "# Define the loss\n",
        "squared_loss = tf.reduce_sum(tf.pow(y - y_hat,2), name=\"squared_loss\")/examples\n",
        "\n",
        "# Set up the gradient descent\n",
        "learning_rate = 0.05\n",
        "optimiser = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "train_step = optimiser.minimize(squared_loss)\n",
        "\n",
        "sess = tf.Session()\n",
        "writer = tf.summary.FileWriter(\"./Graph\")\n",
        "writer.add_graph(sess.graph)\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "epochs = 5000\n",
        "batch_size = 5\n",
        "\n",
        "# Before Training\n",
        "curr_loss = sess.run(squared_loss, feed_dict={X:x_data, y:y_data})\n",
        "print (\"Loss before training:\", curr_loss)\n",
        "\n",
        "for i in range(epochs):\n",
        "    rand_index = np.random.choice(examples, size=batch_size)\n",
        "    sess.run(train_step, feed_dict={X:x_data[rand_index], y:y_data[rand_index]})\n",
        "\n",
        "# After Training\n",
        "curr_loss = sess.run(squared_loss, feed_dict={X:x_data, y:y_data})\n",
        "print (\"Loss after training:\", curr_loss)\n",
        "\n",
        "# Loss before training: 95.5248\n",
        "# Loss after training: 2.13263"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G6PwDuzS2Fqt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "\n",
        "# Generate Random Data\n",
        "examples = 1000\n",
        "features = 100\n",
        "x_data = np.random.randn(examples, features)\n",
        "y_data = np.random.randint(size=(examples, 1),low=0, high=2)\n",
        "\n",
        "# Define the Logistic Regression Model\n",
        "X = tf.placeholder(tf.float32, shape=[None, features], name = \"X\")\n",
        "y = tf.placeholder(tf.float32, shape=[None, 1], name = \"y\")\n",
        "w = tf.Variable(tf.random_normal(shape=[features,1]), name= \"w\")\n",
        "b = tf.Variable(tf.random_normal(shape=[1,1]), name=\"b\")\n",
        "\n",
        "# Loss\n",
        "temp = tf.add(tf.matmul(X, w),b, name=\"Graph\")\n",
        "loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=temp, labels=y), name=\"loss\")\n",
        "\n",
        "# Set up the gradient descent\n",
        "learning_rate = 0.05\n",
        "optimiser = tf.train.GradientDescentOptimizer(learning_rate)\n",
        "train_step = optimiser.minimize(loss)\n",
        "\n",
        "sess = tf.Session()\n",
        "writer = tf.summary.FileWriter(\"./Graph\")\n",
        "writer.add_graph(sess.graph)\n",
        "sess.run(tf.global_variables_initializer())\n",
        "\n",
        "epochs = 5000\n",
        "batch_size = 5\n",
        "\n",
        "# Before Training\n",
        "curr_loss = sess.run(loss, feed_dict={X:x_data, y:y_data})\n",
        "print (\"Loss before training:\", curr_loss)\n",
        "\n",
        "for i in range(epochs):\n",
        "    rand_index = np.random.choice(examples, size=batch_size)\n",
        "    sess.run(train_step, feed_dict={X:x_data[rand_index], y:y_data[rand_index]})\n",
        "\n",
        "# After Training\n",
        "curr_loss = sess.run(loss, feed_dict={X:x_data, y:y_data})\n",
        "print( \"Loss after training:\", curr_loss)\n",
        "\n",
        "# Loss before training: 3.50893\n",
        "# Loss after training: 0.704702"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}