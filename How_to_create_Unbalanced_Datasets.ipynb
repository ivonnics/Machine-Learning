{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "How to create Unbalanced Datasets.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNMY+0RDOXquXBJ3M5ICboy",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ivonnics/Machine-Learning/blob/master/How_to_create_Unbalanced_Datasets.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P2UMk4cEPzFr",
        "colab_type": "text"
      },
      "source": [
        "## Taken from: https://machinelearningmastery.com/imbalanced-classification-is-hard/\n",
        "\n",
        "## Muy buenos: https://medium.com/strands-tech-corner/unbalanced-datasets-what-to-do-144e0552d9cd & https://elitedatascience.com/imbalanced-classes\n",
        "\n",
        "https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/\n",
        "\n",
        "https://www.kdnuggets.com/2017/06/7-techniques-handle-imbalanced-data.html\n",
        "\n",
        "https://towardsdatascience.com/handling-imbalanced-datasets-in-machine-learning-7a0e84220f28\n",
        "\n",
        "https://www.analyticsvidhya.com/blog/2017/03/imbalanced-data-classification/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-G_7FncpPbDp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        },
        "outputId": "4072f6b4-bce0-4e3d-ecdc-911f4159869f"
      },
      "source": [
        "# vary the dataset size for a 1:100 imbalanced dataset\n",
        "from collections import Counter\n",
        "from sklearn.datasets import make_classification\n",
        "from matplotlib import pyplot\n",
        "from numpy import where\n",
        "# dataset sizes\n",
        "sizes = [100, 1000, 10000, 100000]\n",
        "# create and plot a dataset with each size\n",
        "for i in range(len(sizes)):\n",
        "\t# determine the dataset size\n",
        "\tn = sizes[i]\n",
        "\t# create the dataset\n",
        "\tX, y = make_classification(n_samples=n, n_features=2, n_redundant=0,\n",
        "\t\tn_clusters_per_class=1, weights=[0.99], flip_y=0, random_state=1)\n",
        "\t# summarize class distribution\n",
        "\tcounter = Counter(y)\n",
        "\tprint('Size=%d, Ratio=%s' % (n, counter))\n",
        "\t# define subplot\n",
        "\tpyplot.subplot(2, 2, 1+i)\n",
        "\tpyplot.title('n=%d' % n)\n",
        "\tpyplot.xticks([])\n",
        "\tpyplot.yticks([])\n",
        "\t# scatter plot of examples by class label\n",
        "\tfor label, _ in counter.items():\n",
        "\t\trow_ix = where(y == label)[0]\n",
        "\t\tpyplot.scatter(X[row_ix, 0], X[row_ix, 1], label=str(label))\n",
        "\tpyplot.legend()\n",
        "# show the figure\n",
        "pyplot.show()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size=100, Ratio=Counter({0: 99, 1: 1})\n",
            "Size=1000, Ratio=Counter({0: 990, 1: 10})\n",
            "Size=10000, Ratio=Counter({0: 9900, 1: 100})\n",
            "Size=100000, Ratio=Counter({0: 99000, 1: 1000})\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAWAAAAD7CAYAAABUt054AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+j8jraAAAgAElEQVR4nO2df5gU1Znvv6d7apgeQWYATUIPOhizmCAjrLjqynWTsJEsBjIx6xg11+t1E5ONiStmUXziA4PXXEa4u7pubp7srt5nk0cljIoDhPgjq+ZmYRdd2IFBUNabyI9pzC4MzLgyPXRP97l/dFdPd/U51VVdv6vez/M0Q1d3VZ+pOf2tt97z/mCccxAEQRDuE/N6AARBEFGFBJggCMIjSIAJgiA8ggSYIAjCI0iACYIgPIIEmCAIwiNIgAmCIDyCBNhmGGONjLHnGGOHGWOcMfZpzeuMMfYIY2yo+HiEMcbKXp/PGNvDGBst/pzv+i9BEHB2LtfaNyqQADvDDgBfBfBbwWt3AugEcBmADgDLAHwDKEx4AFsAPAWgFcCPAWwpbicIL3BqLkv3jRScc3qUPQAcBvDnAAYAjADYBKCpzmMNAvi0Zts/Abiz7PmfANhV/P91AFIAWNnrRwF83uvzQo/gPfw8l/X2jdKDLGAxXQA+D2A2Clfn2xljFzDGhnUetxg89lwA+8qe7ytuU18b4MUZWWSg7HWCMItf57LevpGhwesB+JTHOefHAYAxtg3AfM75jwC02HDsyShYIyojACYX/V/a19TXp9jwuUQ08etclu6rEe1QQxawmHJ/1ygKk8UuPgRwbtnzcwF8WJx02tfU1//Txs8nooVf57LevpGBBNggxdu2D3Uetxo81AEUFh5ULituU1/r0KwGd5S9ThCW8clc1ts3MpALwiCc86MwaD0wxiYBUCdeI2OsCcDZ4tX9JwDuZYz9HAAH8F0Af1187y8B5ADczRj7EYCvF7e/ZssvQRDwzVzW2zcykAA7wyEAFxb//3Lx52wUVqX/BsBFAPYXtz9R3AbOeYYx1lnc1gPgbQCdnPOMO8MmiCqcmsvSfaMEi5jLhSAIwjeQD5ggCMIjSIAJgiA8ggSYIAjCI0iACYIgPIIEmCAIwiNMhaHNmDGDt7e3OzQUIurs2bPnJOf8PLc/l+Y14SR689qUALe3t2P37t32jIrwPX39KWx4+RCOD6cxsyWBlUvmoHNB0rHPY4wdcezgOtC8jh5uzm29eU2JGISQvv4UHti8H+lsDgCQGk7jgc2FmHknRZggnEY0t1ds2ot7Nu1F0gVDoxzyARNCNrx8qDRBVdLZHDa8fMijERGEPYjmtpqOphoaff0pV8ZCAkwIOT6cNrWdIIJCqsYcdtPQsOyCyGazGBwcxNjYmB3jcYSmpia0tbVBURSvhxIYZrYkhBN1ZkvCg9G4TxDmNUBz2yx9/SkwTFi8MlLDaVzT85rj7gjLAjw4OIgpU6agvb0dfuypxznH0NAQBgcHMXv2bK+H40tECxIrl8yp8JMBQEKJY+WSOR6O1D38Pq8BmttGKZ/fMcZqiq+KG+sell0QY2NjmD59um8nKWMM06dP970l4xXqgkRqOA2Oykm37oZ5SLYkwAAkWxJYd8O8yCzA+X1eAzS3RfT1p3BNz2uYvWo7rul5DQ/27a+Y3zmTxcecdkfYEgXh50kK+H98XqK32LZz1WcjI7gigjBvgjBGtxBFNzy966ghi5cxQKbNTq57hGIR7qWXXsKcOXNw8cUXo6enx+vhBApabPM3NLeNoxfdoIcSY2iIyS9kTq57BF6Ac7kc7rrrLrz44os4ePAgNm7ciIMHD3o9rMAgm1yy7dpbPLfCdaIIzW1zmDEa4oyVXGuTmxqQzcml+szZccfmueuJGHZnoLz55pu4+OKLcdFFFwEAvvKVr2DLli341Kc+ZdeQQ42ZxTZKzpDjRGZV0Oe2U9lmsuPKIne0UQ8JJV6xnjF71XbdzxtOZ3XnuZXf01ULWLbgY+XqkkqlMGvWrNLztrY2pFJklRmlc0HS8GIbJWeIcWJeA8Ge206dE73jfuYScRmR3//4NLQ2T4TpTWqolD0jLgbZPLf6e7pqAet9gaNuQdlFPVfjzgVJQ+ef/MViaF5X49Q50TvuaGZcuM/eYyPIl5nAw+ksVmzai91HTuHhznnCu0ARonlu9fd0VYCd+AInk0kcO3as9HxwcBDJZDQnvdMugqgnZ8hw6sIU5LntxDnp609Js9j0stvOZKqFlQN4etdRLLxwWum7UR4rLApXE81zq7+nqwLsxBf4iiuuwLvvvov33nsPyWQSP/3pT/HMM89YGWZgcdoSi3pyhgynLkxBnttmz4n2zu0zl5yH1985UfH8+T3y23oj2W1aOIDv9u7Dik17K+4WtYYMIJ/nVv/2rvqAVy6Zg4QSr9hm9Qvc0NCAH/zgB1iyZAk++clPoqurC3PnzrU61EDitItAz18c5egIJ+Y1EOy5LTonDBMpvuXzQ+RHfWrX0YrnT+86qusiqLe3e45zoe+23E/c2qxI10Ws/u1dtYC1pr5dK6NLly7F0qVL7RhioHHDRSDyF0c9OsKpeQ0Ea25rrdjfvWAqdv3mdOl2XltxDCicO9Gdm5Z6BdYM6WwO33thP/IcFeMZy+al+1j927sehmZ0wYcwj1cuAlqEonktugjr+WXL54efFnFF/uJ0Noe12w5I/75W/vaBT8QgJjATUmany4CiIwgjVqwWdX4EYRH39GjWEbcadcQIGUauxna7DCg6ItyIQhuBytvuWjV2RSSUGD7+wM9NF8jxCifu6MgCjiB2J1Q4tQhFeI9ogWzlc/uw8tl9FdvMlgSKMWA0mw+M+ALO3NGRBRxB7HYZOLkIRXiL6GItqptgqOJY8X3JloRv3VNKjKEhzpAWLLxp7+ge7NuPjW8cQ45zxBnDzVfOwsOd80x9HglwBHHCZRD1RaiwYlYo9eJxmxvj+P6XCgJ1z6a91gbmFAz48uVteH5PSncx+8G+/Xhq19HS8xznpedmRDgULog77rgD559/Pi699FKvhxIIyGUQDLyY19rF2ZZm462O4jW6TZzJ5HBPsfuwX8nmOF5/50TNxeyNbxwT7i/bLiMUFvDtt9+Ob3/727jtttu8Hkog0HMZOFXBijCP2/NatDirxBiUONMt16gSJH+uHseH0zXv6GS/q9lz4L4AD/QCrz4EjAwCU9uAxauBji5Lh7z22mtx+PBhe8YXEepNqCCBlhCQea339xP6e/McLQkF/zk2HhqBrYURV1xcUi8ibrJDibsCPNALbLsbyBb9SiPHCs8By5OVsE6thAo9gVb3j6QwB2Re17rAyvy9I+ksbr3qggqfZ1gx6oq7+cpZwvNx85WzBO+W464Av/rQxCRVyaYL2300UaNKregImUCv3XYAY9l8ZFORgzKva4UfyqqAxRgLtfiWR2cYNRzUhbZgRUGMDJrbTrhKregImUCfHs1WbYtUKnJA5rXs75caTuPeTXshq3gQZtdDS0JB9/K5dc3ThzvnmRZcLe5GQUxtM7edsJVa6ce1oiPMhqn5NdbTdjyc16dHM/jtyJihlHK9v5+83Ex4eeym+di75jpPjQR3BXjxakDRTAIlUdhugZtvvhlXX301Dh06hLa2Njz55JOWjhdGjLRO6VyQxJcvT5YWEuKM4cuXTyzWyQS6JSEOVYpMKrJH8/r0aAap02mM58UlFbWsXDIHSpza2AMFd4Mf7s7cdUGo/jCbV4s3btxow+CCj9kV7nL/34aXD5VSStUbzhzneLosuFwWvgagZhW2UEdPeDSv/31kDHmNeyCdzeG7vftwz6a9pZX6ct/mfc/tszSmMOCnmHf3w9A6uny1MBEW6l3hVt+n7qf19nEAT+06iqd2HS19kXeu+qzwWDKBjUS9YA/mdSYndhyoPlv1p3q+dx85hYyBeN4w09qsYM2y+ny+ThCKRAyidgiZbIEtzpjhMoKp4TRWFDOZtCvGeoHrVC/YGRrjMakIa0lnc6aztMLGV6+6wPKimd2EIhU5qpQvqsnKAaqWr8x/a3aFW9vVwEiNVKoX7AxTmszZT2GOZjDC9oH3vR5CFbZYwJxzMJMZIG7CQzDxRE0LtQVDRMQYw+xV2zGzJYEvX56saHS4cskcfLd3X91fTDUGuJZvN6j1gv0wr0+PZvDvI2PI5PJojMfwkalNaG1uxOnRDE6PZsE5B3elYU/wEYVLeo1lC7ipqQlDQ0O+FTnOOYaGhtDU1OT1UOpGFMFQq0mhSnnTwef3pLByyRy813M9dq76LDoXJC1bRadHs7qRFUAwi//4YV6rUQ6qmyGTyyN1Ol0S5Vw+j/HRD3Bk2H/CQhjDsgXc1taGwcFBnDhxwo7xOEJTUxPa2oIbayzyoerJAoM4q0nkd03q+IZznJtu9y36jCDWC/bDvP7tyBjG89Vn/8QxhlyeIw+OI8NZ/PUbpz0YXfCQhUt6iWUBVhQFs2fPtmMshAQzvlJ1cUxW8q/8WH39KZw5O171noQSr2g3LwpRMzveoNUL9sO8Xrpqu/R8J5SYsGg4IUaJMXQvn+v1MKqw7gN2oAoUUYnMh6oVxIQSx2cuOQ8rn5XHeqr1XbWhYSraMJ1y4dT6oc+cHcdwuvr21+++3aCg12uNxLeaGAM4R2mNRLve4UcDwJoAB6QKVNCRtZsXLap1bz2ArOC2VeX0aBbtq7ZLy+k1NzYYnqhfuOxjNTsHEPUj+rtHEdlcrYIDj94035dCK8OaAAekClTQMeNDNdptQDahZRaXKJni+T0p4UUgSF8AP6OeRz93kHADo2sReQDdWw8Eav5ZE+CAVIEKA275UBkKYqv9LFkyxevvnJBmxhHW6VyQLPngo4zRhWCRS8zPWAtDo+pmvqPVRA8vERzA2m0HqrbXSvQgnEMUxhdVWhIKkiFaY7BmAS9eXekDBmypAkXUz/UdH7NcPPv0aBYP9u3H6++cKEU/yKAFN2dRFz6j7gdWGUlnsXfNdVjw0CvCxIpaBojfikJZE2CHqkAR9fP6O/bErZaLuOz2jwG04OYA9YT+RQX1gr9m2VysfG5fRbNQJc6wZpk81MyPRaGsh6FRdTPf0NefctVXyBGiamYuYMT6uvXv/hk7f32q9JzEd4LyCJt6knv8WBSKqqGFBPXq7iZmO8BGmVrW14N9+0Pdd80sccZw1UWtODyUlgqs2YVpPxaFIgEOAX39KUtFdeolxzmu6XnNcz9aEJBZX/ds2ovvvbAfZzLR9fGe0xjHaCbnuE/Wj0WhSIADjmpZeVVqMDWcLmXekQjL0bOyoiy+j7mYOCFLaPJyHYPqAQcEWUPNtdsOeL5Cns1zdG+tDl0jJqBoETEbXj5kqKa0HXQuSGLdDfOQbEmAoVA3Ra154hVkAQcAmf9w95FTujVO47FC1Sw3CFoAvNusXDIHKzbtpUU1DW5HIvitKBRZwD5DZOnK/Id6LWZijP64fqJzQZLEV0J5c9ioQd9RHyFrHS8LLdPz+57bpOgW5bEbqxl4USBMGVz1oMTkUTNRzagkAfYRMktXFu4l296SUDDisktALwCeKBDFlGJ1iiZbEthw42XSi1BUfeTkA/YRMisgxzkSSlxYjlJUDrJ7+Vys3XbAUA8sWUcMs/jJr+ZXolTdrCWhoHu5uP273yIRvIQsYB8hswLU1Vrt6u3DnfOE2wFg2KD4mpn4Mos76rfWgDxKRUvngmSoE1ga4wyP3TQfe9dcJxRfP0YieAlZwD5CL07R6Ort7iOn8PyelKEFH7WAuxFaEgoVYJdgtsaAn9vDL4/twH0NvZjJTuI4n4H1413Yml8kfG9LQsGZzHhFPYZ4rGDT6aVd+y0SwUtIgH1E54Ikdh85hY1vHEOOc8QZw5cvl09W0Rf/6V1HDa+2dy5IGr4dHk5nqQC7BJnvvnvrAaEI2eX2sZvlsR3oUZ5AM8sAANrYSfQoTwBZVIjw8tgOPH7eNuRHBnE8Ph3r+YRIq7/32fG8r4re+BUSYB/R15/C83tSJQspxzme35PCwgunCSeu2W7JVqEC7GJkvvvhdLYUH50aTmPFpr14dvdRjGaqG6HajRlLVuW+ht6S+Ko0swzua+jF1syi0nEfaXwSGDmLGIC2WLVIi2LCvS5641fIB+wj9Ko1ibAaujN/7Ss4p9HcqnxUw4X0MLqCzwHs/LV+8owdqJZsW+wkYmxCJJfHdujuN5OdlGwfKv3/voZeJHC24nVVpGtBc6caEmAfYbZak9XQneF0FulMDnFBfKYsZDOq4UJ6+C28TM+S1eM4nyHZPr30/5mxIeF7VJFOKHFpTDjNnWpIgH2EbILKttvxxc8DmDKpAS2Jyi+NKIeDFtzEiFb2vUxMMWLJilg/3oVR3lixbZQ3Yv14od53QoljLPFR4b7H+fRSRMOaZXOr5iXNHTHkA/YRZqs1lRel1lvUqbXoM5LOYmZLQui7izOGPOe04FYD7cp+X3/Ks9oPx/kMtAlEuNySFbE1vwjIoug7HsJY80exPnsTtp39vVLIYnP8IWEbsrZl67Czo3JtwE+tf/wK4yZCYhYuXMh3797t4HCIentWXdPzmlBk1S9OvfWCGYBHb5rvypeJMbaHc77Q9gPXwKl5/WDfflNRKXahjWYACpbsquzXSgtlCSUGgEkr6SVbEvLF1oFeakNmAr15TQIcErQhaYA8W84Mrc0KxrL5quM6ETzvJwG2q3lj+XFijNkWA3xOY1y3jnApCiI2hPf5dDyS7SoT33gpYad764GqO58/bvwnPHTO82hO/5YE1gb05jW5IEKCrEeWlY66CSUOzuG7PlpOY2fzxnLXhOwiOakhZqqcpxJj+P6X5mH3kVNSC3trfhG2ZhaVLsJ73jkBJkmKKL9I/LfJb+JB/gQa0mOFA40cK7gcABJhByALOOTMXrXd9C0wA0pfVD0/Zvn77BBjv1jAeu4cqzHQIssaAFY+u89w9brWZgX9q6+rOp7MwjY17kcvLYiulqmzgBVvGTsGUQFZwBFG1gdLhvbLqrfAV14yEwhPlpOTzRv10nBF7gAR5XU+yo83e9V24ftNjXtk0Nx2whIUhhYAjBZ6EWEmVE2JMQyPZtC+ajvaV23H/LWv4DOXnFdz/7AV1DYbDmgHnQuS2LvmOhzuuR61SvWYHZ+pcU9tM7edsAQJsM+RFWmvJcKqaK/YtFeaVFFOS0JBHpUNIofTWWx68xi+fHmyFOMqI0xZTqKLliwc0MrFUcbUhDyGWC8s0cy4pSxeDSgawVYShe2E7ZAA+xyz6clAtWjX6rqbbEngnEkNwv5x2Twv1X94r+f6SBTUNloysd6LYy1k1SoZg270iS2lHju6gGWPF3y+YIWfyx6nBTiHIB+wz6nHH2km8kG1kFboVEUr/yw/tvZ2AiMlE/Uujlb84dJazry2n92WUo8dXSS4LkEWsM+px69n1B0QZ6xkIekdr/w1Kqg9gVOLdbb7oAd6C9EN3S2FnwO1C+cQ7kAWsM+px+I0EvlQnkzR15/CqTNnpe/VfhYV1C4gO89W3TG23mUM9FamDnsd10tZdBWQBexz6rE4Vy6Zo9uBtvwYE8kBeQdGH25sWfQSYOtdxqsPVdZtAArPX33I0hjrQr0YjBwDwCcuBhG2yMkCDgBmLc7OBUlpU05RnG8tf3GYs96sIMs+tONc2XaX4ae4Xr2LQUStYBLgkCJbyDk+nK7InjKSexWmEDO78b07ZmqbJLPNg7heMxeDiLgqyAURUmR+SA5gxaa9pdApK8ciAoCf4nqNJnlEyFVBAhwiypMCzpwdhxIX+4HN1IYIY4hZpPBTXK/Ri4Gf/NYOQy6IkKCttDWczkKJMbQ2K4Z7kDEUsrAYK7gwqJB2SFDFVr2lV4XMqgibdRNoxyHbx09+a4chAQ4JosW0bJ6jubEBw6PZmlavHZW+CJ/iRChavcc0kuThJ7+1w5ALIiToJQXU8uGSmyHkOHFL76SbwE9+a4chAQ4JetlTonhV1Tsc5Uy2yODELb2TbgI/+a0dhlwQIUEve8rJeFUiADhxS++0myAi9ShIgENCLZH1fbwq4RyLVws7GVu6pXfimBGEBDhEkMgSQoxGH3h9zAhCAkwQUcCJW/qIuAmchBbhCIIgPIIEmCAIwiPIBRFBRK3RyXdM+JKQF+UhAY4Y2pTlMLaVJ0KC34rJOwC5ICJGPU0+CcITIlCUhwQ4YjjVx4wgbCcCRXlIgCOG7Q0fCcIpjNYPDjAkwBHDqT5mBGE7ESjKQ4twEYPqQhCBIQLZdiTAEYRSlonAEPJsO8a58QY1jLETAI44Nxwi4lzIOT/P7Q+leU04jHRemxJggiAIwj5oEY4gCMIjSIAJgiA8ggSYIAjCI0iATcIYa2SMPccYO8wY44yxT2teZ4yxRxhjQ8XHI4wxVvb6fMbYHsbYaPHnfDv2JQiz+HUu19o3TJAA18cOAF8F8FvBa3cC6ARwGYAOAMsAfAMoTHgAWwA8BaAVwI8BbClut7ovQdSDH+eydN/QwTmP1APAYQB/DmAAwAiATQCa6jzWIIBPa7b9E4A7y57/CYBdxf9fByCFYvRJcdtRAJ+3ui89ovcI61zW2zdsj6hawF0APg9gNgpX2NsZYxcwxoZ1HrcYPPZcAPvKnu8rblNfG+DFWVVkQPN6vfsS0SSMc1lv31AR1Uy4xznnxwGAMbYNwHzO+Y8AtNhw7MkoWCMqIwAmF31Y2tfU16fYsC8RTcI4l6X7akQ78ETVAi73d42i8Ae3iw8BnFv2/FwAHxYnjvY19fX/tGFfIpqEcS7r7RsqoirAVRRv2z7Uedxq8FAHUFg8ULmsuE19rUOzotuheb3efQkCQCjmst6+oYIEuAjn/CjnfLLO42n1vYyxSYyxpuLTRsZYU9lk+gmAexljScbYTADfBfD3xdd+CSAH4O7iMb5d3P6aDfsSBIBQzGW9fcOF16uAbj9QWDn+w7Ln3QCequMYXPNoL77GAKwHcKr4WI/K1d4FAPYASAP4VwALyl6re196RO8R1rlca98wPagYD0EQhEeQC4IgCMIjSIAJgiA8ggSYIAjCI0iACYIgPMJUJtyMGTN4e3u7Q0Mhos6ePXtOcg9aEtG8JpxEb16bEuD29nbs3r3bnlERhAbGmCd92WheE06iN6+jWgtigoHeULe9Juqjrz+FDS8fwvHhNGa2JLByyRz/dpKmORxYoi3AA73AtruBbLrwfORY4Tlg7wSmL0ig6OtP4YHN+5HO5gAAqeE07tm0F/ds2ouEEsO6Gzr8I8ZuzWHCEaK9CPfqQxMTVyWbLmy3C/ULMnIMAJ/4ggz02vcZhK1sePlQSXy1pLN53LNpL9pXbUf7qu34ne/9HH39KZdHWIYbc5hwjGgL8Migue31EKEvSF9/Ctf0vIbZq7bjmp7XvBUmCxwfTtd+U5FMjlcIsutI5/AxoLsFePRSutj7mGi7IKa2FS1TwXa7cEPkfYDotv2BzfsBwD+36waZ2ZJAyoQIl1Muwod7rrdrSHJkcxhAxR0XQC4JHxJtC3jxakBJVG5TEoXtdiETcztF3geIbtvT2Rw2vHzIoxHVz8olc2BHB0jVKm5ftR23/t0/23BEAaI5rCWkd1xhINoC3NEFLHscmDoLACv8XPa4vZaCGyLvA2S37WZu5/1C54Ikbr3qAluPufPXp0pifMn3fm7fgbVzWEbI7rjCQvhcEGYjDjq6nL01U48d8igI2W37zJYa1plPebhzHhZeOA0PbB5AOpu39dhjOW6vq6J8Dj96qfNuNcI2TJWjXLhwIfd1wLo2JAcoWJt2W7VEFVofMAAklDjW3TDPsA+YMbaHc77QqTHKMDOvP/eXv8S7/3HGsbFYFmPRdyCmAJOmAOlTAIsDPFewmD9xHfDuK6E2DPyA3rwOlwBLr/6zgBVvVW+PcHyuE4kGVo8ZBAEGCr/n/c8P4Oy4vZaxFl0x1pu75a8lWoHMh0AuU/sDyVhxhOgIcHcLCgX9tTCge7hyU4StZZG1CgCtzQrWLJtrSYitiHBQBFilrz+FtdsO4PRo1oFRVVIhxmbmrswokSEzVoi60ZvX4fIBmwkr04vPDbkAyxINTo9mLYWOhSkUzQidC5IVv9cl3/s5xnLOdJgp9xkfbF2NZqNz14z4ArRY5zLhioIwE3EQkfhcEXqRCVZCx2ShaGu3hbKhbRXvfH8pDvdcj8dumu/o5yRG3xe/MHKsMvHiZ/eaPzgt1rlKuCxgMxEHbiRhqPjM11wr0UAm0LXcC7L9To9m0defCqUVLEJrGdudIZdDDA2Q+J9HjgF93wJ+dg+QMblYGMLwSL8TLgsYKAjbircKPt8Vb8mFzq34XB/Wgli5ZA4SSlz6uih07MG+/VixaS9Sw2lwTLgXytON9ULOgpiQYReHe67H4Z7r8Ynzz7HleDGZ+Krks+bFl8WBy24JvfvNb4RPgI3iRhIG4MtaEJ0Lklh3wzy0JJSq1xJKHCuXzCk97+tPYf7aV/DUrqNVy5tad0X5flqCmJBhN7+499O2iPFxPsPGURXhOWDfM1Q3wmXCFQXhR8xEZtiEmUgE9b2p4TTijCHHeelnS0LBmcw4sjoLSwzAe2Ur9PPXvoLhdHVUQEtCwTmTGnTHFLQoCLu49e/+GTt/fcrw+5fHdqBHeQLNzEBomVlYHOB5X7jKwoLevI6uBewWLteCUCMR9FwF5XQuSJZcErnixVj9OZzO6oovAMQYqzj23JlTqt6jxBjOZMYNjylqPP31q0uWsRG25hdhVfZrcCTggufgF1dZFCAL2Glcjje+puc14QJbnDHkOcfMlgQ+c8l5eP2dExVWr+XP/fg0zD5vMp7adbTqtUkNMWHSQrIlgZ2rPlt6HlULWMbsVduF904q/zrpTkxjHzo7CIoLtkx04oD9iEO1IGRuBpmvVRXZ1HC6QiTtEF+gUGxGdhstyxgjv7A+5a4dUSRFCxwWXyASYZleQgJslnpCymwu+NPXn8LK5/aV3AOp4TRWPrcPgLVatm4T1EI9XnBYIMbH+Qy0sZOOfu5gfjooMtg5SIDN4JP+W2u3HajyzWZzHPf27sUtV16AjW8eQy7vTEZWPTAATUq8qu+HK1wAABaESURBVFCPXtQEIackxgNnMPr8Xc4sxgHI8AasH+/CVreLzEcIEmAzuJy+LHMzyGoP5Dmw6V/8Jb4AcOtVF2DhhdOC02U4KHR0oRko3pEdA+cAs6OSfJGzPI6t+UUV21zv+BFySIDN4GL6sqiuwopiZ149akUtuEmcMdx85Sw83DkPQDjrQXiOeuHfcheYkYpnJpjMzmJ5bEeVCKuQGFuHBNgMLqYvr912oKqugn+ktTYMwF90XUai6wavPmSs3KRJGAMeU36Ix/BDHOczCu4IEmNbcV+AfVYXwRSLV4tDymxOX+7rT7lS4tBJOArpxyTALuBgpEKs6NJoYyfxv5S/xeW5f8Pi2F7MZCelokxibBx3BdiNRSwrAl9rX1lIGVCsu2rPRSUsdRMozMwldDsj20cjG8dt8X8o+Znb2En0KE8AWZBlXCfuCrDTi1hWBN7ovtqQMhsuKm4W9nYTCjNzicWrgS13OeKG0KJd5GtmGdzX0IutGbEAl0NiXI27qchOL2JZKXwj2/eFb+qnY1ostqPG9IZNfAH94jyEjXR0AV/830CjPdXWzJKsIxZZ7RBtd6nOoOGuBez0IpYVgZe9h+f0LVrZrZ/BW8INLx/yVeQCEWC4sz3qpB8L6EZL1CLKlrG7FrDTNXhrFb4Z6C34artbKjsH6O0L6Fu0TFJXV7ZdQ5j9pGHxZQcC0Z2YS8QYcF+DPUV7omYZu2sBO1QXoYRelEItX61o33L0LOQa2/XKQ05NKMLyjWEgzBcX3+FxzYaZbMj2Y6oi3MCA/7cunJax+2FoNtdFqDo2IBb4Ry/VXwBU933hm2JRlVrXsyRulVkACp0kyovfpIbTWPnsPuw+cgrbB94PrfgCtAjnKolWIG28prDdHOfTHTv2OJ8Q42s+Pg1Pf/1qxz7LbcKTiKENIbvhbyuF3oh/WH2/mVhfmdX9iesw+sgleGj0fXyzsTJeMpvnwrKNYYJqPUSLtt/7Ig5/4XrHXQc7f32q9BlNcYZ3vr/U0c9zmnAIsJFQMNkCYKK18rlZN4no/Z+4Dtj3TKF1ODMWLxkmWpsVrFk2l5Iw3CR92tvPf/cVAJWLaGY7fZhlLMcDbxkHryB7uaWriqfs1qu8mPRAb6FbbF5zyx9vLITw2OkWefRSodgP5mdgUeZx+z7HRzDAcpEdKshuAcmcc5XuEelLHWtewgdnJeslNvPVqy4o1R/xA8EpyF4rE01r6dbyeWndCy/eX71PLmM5EUS7yLZj7BhERanqiZcMAq3NCvpXX+f1MKLN4tXA5m8AtTomO8nP7gW+8JfClwbWfr70/8/95S/x7n+Y7Npsgqd2HS25+PxuGfunJ5yR9u1mQ21YrHJ/2W2ahRXk3v/zF1j4wrX4x/SX8I+Nd+PyD36BHBef1pyPTredDIcwiSRwdHQBiRZvx7Dn7w29za7u0EZQfcZ+DWvzhwU80CuOPtCmKZsVSm0Shc2JIP+y9W/whSM9aI4VUkBVX29cYoXItgcdinbwCR5GQQAofN8Gek3dTf7i3k+X/u+0z1gVYW0nby/xXoBVy1cWTzsyOOGaqKcgY7mIG6hmphez29efQvfWA6XQsR2N60viq9LMMpC51cNoAVO0g49gcfn3yC0sFNcqdxX09adq1r6uF44JMT53UrzCPeI23gtwLbdColU/QcIIquVcI8Khrz+Flc/uQzZf1mvt2X1IHvsZ5r79KJaPvo+FfAbWxwohZTNN+nRjIbOA44xh3Q3zKNrBL3gtvoBtxbU6FyQrDB+nxPiDs7mSGD9203zX57I3Aly+2KZn1appyzLxTUwr/EyfLohp5oz4NmxqW+04YQDdWw+UxFflj/CPuPRfn0ACmaqQMllTxBxiaBCI7XE+Q/67BoyEEifx9RuypCC3sTkrr1yMAXGHaDu4p6zjjFuRFO6FoZUE8BgKXpgan8viwJd+BGy+U/JeBnQPV3+GNtQspgC/exuw75lq18OyYkhYUZgH89OrCkzvaLwbbbFqkR3MF5IrepQnKpoijvJGPJu7FjfGf1W1fVX2a6GIA0461NONwtAsoo0S8goWLxQGcqHhgpOLa+c0xvH9L1k3MrwPQ6uaGDXEVxVHWegYoLNwprU888CBF8RpyC/eD4ynS6+1xaoTJmRuhplsqPCebKEQyUw2hON8QsD35H9HuD3oRK1aVaColU7vFupnu9A1XJ2PTrgpzmRypT6MjhkdrljAhoPEWeVVc6BXXGg6pgCdP6z+oz4y25aV4PKECT0LOKxJFXo4KcBkAdtEdwt81UGwPCHKJZyINVbv282KsfcWsBGfkOiPJGs2OGmK+IpqUxhOeWUnmZth/bj+FX15bEfRApb3zgoazUr4ojhCiUstigzjQaW28vA2u8RYvaSlhtN4YPN+ANY7fbvzjaoVZysrdiP7wzmc915e2WlrfhFWZb+GwfwM5DnDYH5GTV/u8tgO9ChPoC12EjE24dpYHtvh6LidJpvn6OtPeT0MohaiuttewmLiGtwuUZ748ZEpjbYcM53Nlepd9/WncE3Pa5i9ajuu6XnN1HfEfgtYlE4srLVbNOinzpI76s0mTiSmWbaCRdbt1vwiYc8rmZV7X0NvhcUMmOud5VeyOU6djoOANtySxSLjE67FG9/7XOn/2rh+sxwfTqOvP4UHNu9HOlv4Hc1ax/b6gEWrsIJoA8Oro3rHU/ctF3ylGciau9U4E5+K01nF9GKZauWKIh0eU35YauddTp4zXHT2aVPj8xtOZhGRD9gh/BIdoeKBT9goaiJWajhdM1YrWcwATQkaDyRbEti56rMA3PQB6zWoXPGW+aterdKQ2oklFF/5aeQAmsdHcBozcE/2T035aPWsXFl8sKxotd/8xQkljiYlJmwUSmnHAcQv0REqHnfv0EObACITYzUDdIUk8sJoNxh7BdiJrsd6HTQMFeeRX8NY8R9Rvd5aoqgXnnZP9k8NL9xpLWmvawerK7wAKm6tAEo7DjTqd2jz170dB2BfE16HEYmxtkSBKtBajBoq9gqw012Ptdh4JW1mGaxp+Am2ZhYZEkU9K1cvPliLX/zFssw2WV0MIoB0dHkvwHY24XURbTaeysolcywZKtYFWFsgPaZUZqI5ccKtFOfRYRr7sGT51hLFWuFpsoU7LXqWtFvIajrIJh0RQErfGQ9RzgGWPebZApwTqN+Peg0VawIsKpAebyxGI5x2JhXRzIJCvFEcRyyBMeCvlB9KXy8vqK5n5Zrx6Zr1F9sN1XSIAH5ZhMuOevv5DmHFULEmwCIfbC4DNJ4D3P+epUOb+kwBHMDuyx7GFW/3mApNY6JWFkW05SRFVq5Zn269iR524FR6JeEzzDYycAxuS6W0MGFNgJ1YdKv3M7Vw4PI99+Ns41RMsumjjZSTNOvTNeMvtpPWZqUUJkOEHD9FHfgpQ88HWBNgvUW3Wv3d6mGg11BQOecFS5aBY1J2GBwQ9mgzi5FykvX4dI36i+2E2ghFCL+lJhMlrKUii1IelUShLXut/m5mqdU5AwXhVcW3HJn4cg7kuDFpNuoWGMZk8f6YhB2Nd+M3k27Bjsa7PU9LpnjeCOG31GQP0pH9ijUB7ugqZKVNnYVCJbNZhefvviJPyKiXGn6sNCbhz7LfksZFaBP+8hz4Se4PwWRJGhwYyk82XP9B9jkqzRjzrDaEEq+8yFA8b8TQfk9Z3NvxbP56oXIhCbENYWiiRInNd4rfa9QXJXBf8JFBoSXLAbCps7Bt6n/H1n+7BPfxXmFUQblVzHnBKl4c24vTfDKmsw+r3n+KT8blmb81Nt4yWgXHAlCVmuxUrO+5k2L4zpWtuLBFASuesTgDGGPI5TniMYZzEw1obvwAb7/9ga2fbZSmpia0tbVBURRPPt8I2WwWg4ODGBsb83oouhg+l+XfUz9ERaRPFUrNqmOLKM6Uo7SSkKGdHCPHML7lO/iAn4NpAnE7zSejKTOOPz76P/D7jdPxan4+bmP/oBvNoL7Wxk4iwxtwlscxiU24NkZ5I9aO31Z7rAKGMRnTIBZhLU7E+n7nylb87sdnoqF5CljZSeho87hleRHOOYaGhjA4OIjZs2d7PRwpg4ODmDJlCtrb2yvOo5+o+1xqU/y9qh2cy0Q+KsKZcpQy37CRhAyBq6EhN4ZWfAhNuzac5XFMxhia0+8jBo622EncGP8VzqDJ8FAb2TgakcM4jyHPYcrdIMJEbSNHYn0vbFGqxLcx7p86vowxTJ8+3feW5djYGKZPn+5b8QUsnsuOrkJ9lu7hQoKEV/gpQsMD7M2E00Y71BMFIVmtLUQ1TAjcKT4Zk9g4JrPKydfMMhjKT0YMjVXhYDIYAxqQLy20WQkBk7kgtIuDTsX6MrAq0fjIVOMXJDfws6iVE4Rx2jLGhkmmqwjaRkDqQjiFvZlw2nqfZm4tBnoLPdpqoM63KRiDgnHhe1rZGdyT/VPc19Bbyl4zMk/t8MvKMttO8clI8yZPesS1NttThJoIKQ43OJASbwxkXQg7sXZvqld+0gxq7zcTGWuNbFwqqgwc9zX0Yv14F/4s+y1kTVxnkuykpeiE9eNdGOWVgqf6lBdlHsdFZ5/GoszjromvF+6Hl156CXPmzMHFF1+Mnp4e1z8/TLhyLr2yQi+4OtL+X8CqANuVCffi/aZqNtSClYV6dSs/QSOrtpRlvlrGYClErJ4WRvWiDS/TEmPMdfdDLpfDXXfdhRdffBEHDx7Exo0bcfDgQVfHEBZcO5dexQkfDnaLLjtwLhPODDY109TSzDJIcLGwcwBpLvYTW3VFuJHZFmcMG/74sooqTJ+55Dw0xAoXm8Z4DB+Z2lTT/SCrc1ovb775Ji6++GJcdNFFAICvfOUr2LJlCz71qU/VfcwgYPd5BFw8l1UtjBjAa6fdW8YPxeE9xpoAi3q92V1+MhYH8tV/qAxvAAevCB8zg1ql7K+UHwpdGW6Wg6yHm6+cJazC9Pbbb+OTBkPOrPazEpFKpTBr1qzS87a2Nrzxxht1HSsoOHEeAZfPpRdxwixWaNRpZ7mCgOFMJpzsJA70Fk64tkNqYprw7ZwDeY34chQWtP48eydWZr+Bca7/KzCGqvC18miHlKS+g1vlIOvhq1ddgIc751k+zoaXD1UUkgYqu70SxgjdeVS/15LvpW1w2FuuIIA4kwknQi9i4o8eAfq+VVnIHROhZxXbAIzypgmfahbSJpjlDOZnCCMQvCwHaRa7a/fK+lYZ7WclIplM4tixCbfU4OAgkslwl7t04jwCHp9L9Xv94+XAe//XgQ9ggLa6oLqAHyEr2JlMOBGyiIkXvlnwNyVaAQA8fapm5bJy98DW/CJcnvs3/Nf4P0hF+DifgUWZx4WveVUO0iytzQrWLJtra+3emS0JS/2sRFxxxRV499138d577yGZTOKnP/0pnnnmGSvD9D1OnEfAB+dyoBc44tRCmWQVPGKJGe4JsOzEqo749CmMx5sQN1A7UuseWDN+B/bkfwfdyk/Qig91Ex5k3Spki2Z+6Vjc3Nhge+F0q/2sRDQ0NOAHP/gBlixZglwuhzvuuANz5861Y7i+xYnzCPjgXL76kHD9xVEilpjhngAbqEnakBtDDoBeraZagrotfxUWx/YKrVmz3Sr81LHY6u2sCKv9rGQsXboUS5cutWOIgcCp8wh4fC6dtkaVhLML+AHAPQEWRUwIkC2pcQ6kNBaoSCBvZL+Sxt2a7VbhVsdiBiAWK1Qrk+FU/V5qvGkPoTyPThZyZ7HCQp/dTRsChnsCXBFraP6PysGq/LhmBdJstwqnOxaXL6qpcaSp4XSh5oXmfVS/l3CdxauBvm8644bgefPlCkKIewIMTJzsOmIM82D4zaRbKvywZgXSbAdipzsWl0c0lFtQTgT1E4Rp1O/r5jthe8nKqbNqvycCuCvAQM3OFmrcbnlEA+dAAyuErJT7Yc0KpNmQM6dD1Lq3HgBQHawfyttZIphYMJrksMj5emW4X6nFoGNfraUwzmNVmWqqm0FW+EYmkPXUaRhDY6nX3FB+sq11HYbTWTyweT/6+lO2HI8gHEGbcGU5QaPYnj5iSRci3LeADTj2y+N2fzPpFuF7ZrKhumJ4jdZp0C7wAUAC9hUMUlEzpsjiJXyN1l/7yGxrNVy0pWsjivsWcI3KS1oLVtYKXnUzbM0vcqTMo94Cn904EWLmJXfccQfOP/98XHrppV4PJdD4+jzq1RBmcSBmoN+f1Ua9IcB+AZbVe1DRyTPPc+DZ3LUVImrWzWAX9URAMAYkWxJgKGSutSSU0v8VnVzpsLWIv/322/HSSy95PYzA4+vzqJcwwXPApCkTC216XZgjlvmmxV4XRK0OGSodXYUrn+YWJsYKnYrXlG3zKlW4nggIzoGdqz4rfK2vP4W12w7g9GhlvQvPQ8z0WkrVybXXXovDhw/bM76gELXzWCuuP326UOOlVthpxDLftNgrwHodMrSTUXLlE1mYbtTX1VJPBERSx5JVIxt8FWJm9IJJ6BPF86j+Xi98U1LXl9cOX4tg5psWWwWYjwwKyzgIt0sW447z6Ui2JNA+PYGdv3amULsRalneSowhW5a5ZtSS9VWImZkLJiEnquexZoiajviqmXBhPj8GsFWA/x0z8FGckGzXICnm3rZsHXZ2FG7j565+CWcy3lXN17O8N9x4mX8s2Xqxq6VU1Inyeaw3w1XNhIs4tgrwusyNWCe4bV+XvRF/pX2zXuv6oj/trdggUo32+XztqmyWbEn4y5KtF7taSkWdqJ9HNUStuwW2Z8yFHFujIHaf+zlhosPucz8n3qGjC1jxFtA9XPipiu+2u4GRY2DgpeaaVjoVAxNxvW2xk4iVNe3UHjdeo3+954tmdiIKCbTBL3fzzTfj6quvxqFDh9DW1oYnn3zS0vF8D53HAmYuOE532wgItlrAhbqomYrb9oQSxzozgiXwp9lRgaxW4Z6WhIK9a66r6u8FoFQcJxlUV4MMvbsQC2zcuNGGwQUIOo8FDFY8REwpREgQ9gqwLXVRJX6zJDuJHY131+0+0IvrTShxdC+fa9/vECSoIpU90HmUX4hE26J+rorYnops2Tcq8adxFNwGQGVBnhfZf0E2V9vvJIvr/Q82o6rPWij8uwThBbILEQmuEPdTkWsh8Kdpq6MBE+4DI+ILiDPqoCTw0Rv+Z+jElnN/L4T4fXwqQRinr8dYKyuW8KEAF1OVRxMfKy3kyTBTGH1rfhFW8zsxmvgYAFZIkwxhHGJTUxOGhoZ8+8XknGNoaAhNTU1eD0UXv59HwOfnsmwxPcpt52vhfjU0I3R0obmjq5Q1tmn064bSgss7SbQ2K7i+42N4/Z0TJV/uoiXfQvOC7zs/fg9pa2vD4OAgTpyojsf2C01NTWhr83eIVhDOI+DjcxnV5BST+FOAi5R8sQPrML7lO2jIjZVek6UFH+653s0h+g5FUTB79myvhxF46DxaJMrJKSbwnwtCREcXGr741wW3BOSF1MNWVYwgAossJjgqySkGCYYAAwW3xP3vINY9jN1f+hV+Ef+DipdDlSBBEEHHoeSUsOFrF4SMyMXqEkTQcCg5JWwwM6u8jLETAI44Nxwi4lzIOT/P7Q+leU04jHRemxJggiAIwj6C4wMmCIIIGSTABEEQHkECTBAE4REkwARBEB5BAkwQBOERJMAEQRAeQQJMEAThESTABEEQHkECTBAE4RH/HwxBfTUeiB2SAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 432x288 with 4 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vG2G10doSc9w",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 241
        },
        "outputId": "bba0278b-dbe2-459f-d215-a6b272095d2b"
      },
      "source": [
        "pip install -U imbalanced-learn"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting imbalanced-learn\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c8/73/36a13185c2acff44d601dc6107b5347e075561a49e15ddd4e69988414c3e/imbalanced_learn-0.6.2-py3-none-any.whl (163kB)\n",
            "\r\u001b[K     |██                              | 10kB 18.3MB/s eta 0:00:01\r\u001b[K     |████                            | 20kB 1.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |████████                        | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |██████████                      | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |████████████                    | 61kB 2.3MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 71kB 2.6MB/s eta 0:00:01\r\u001b[K     |████████████████                | 81kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 102kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████          | 112kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 122kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 133kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 143kB 2.7MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 153kB 2.7MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 163kB 2.7MB/s \n",
            "\u001b[?25hRequirement already satisfied, skipping upgrade: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.14.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.11 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.18.3)\n",
            "Requirement already satisfied, skipping upgrade: scikit-learn>=0.22 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (0.22.2.post1)\n",
            "Requirement already satisfied, skipping upgrade: scipy>=0.17 in /usr/local/lib/python3.6/dist-packages (from imbalanced-learn) (1.4.1)\n",
            "Installing collected packages: imbalanced-learn\n",
            "  Found existing installation: imbalanced-learn 0.4.3\n",
            "    Uninstalling imbalanced-learn-0.4.3:\n",
            "      Successfully uninstalled imbalanced-learn-0.4.3\n",
            "Successfully installed imbalanced-learn-0.6.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cRPLRRQSxGW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "b2edd6d6-3b58-4f9b-b24a-f960b988b69d"
      },
      "source": [
        "# https://imbalanced-learn.readthedocs.io/en/stable/api.html\n",
        "# https://imbalanced-learn.readthedocs.io/en/stable/auto_examples/index.html\n",
        "import pandas as pd\n",
        "import imblearn.under_sampling as under\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "breast_cancer = load_breast_cancer()\n",
        "pd.Series(breast_cancer.target).value_counts()\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    357\n",
              "0    212\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dh30Au4UmfKM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "08d75448-02b1-4947-ad55-838e5ccf1d98"
      },
      "source": [
        "UnderSampling = under.ClusterCentroids(sampling_strategy={1:300, 0:212}, random_state=83, voting='hard')\n",
        "x_resampled, y_resampled = UnderSampling.fit_resample(breast_cancer.data, breast_cancer.target)\n",
        "pd.Series(y_resampled).value_counts()"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    300\n",
              "0    212\n",
              "dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c7RrgTg5pD2t",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 473
        },
        "outputId": "13d939d2-82ad-494f-d957-6def6eba383e"
      },
      "source": [
        "# https://stackoverflow.com/questions/38105539/how-to-convert-a-scikit-learn-dataset-to-a-pandas-dataset/46379878#46379878\n",
        "# https://stackoverflow.com/questions/48769682/how-do-i-convert-data-from-a-scikit-learn-bunch-object-to-a-pandas-dataframe\n",
        "\n",
        "def answer_one(): \n",
        "    import numpy as np\n",
        "    import pandas as pd\n",
        "    from sklearn.datasets import load_breast_cancer \n",
        "    cancer = load_breast_cancer()     \n",
        "    data = np.c_[cancer.data, cancer.target]\n",
        "    columns = np.append(cancer.feature_names, [\"target\"])\n",
        "    return pd.DataFrame(data, columns=columns)\n",
        "\n",
        "answer_one()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>mean radius</th>\n",
              "      <th>mean texture</th>\n",
              "      <th>mean perimeter</th>\n",
              "      <th>mean area</th>\n",
              "      <th>mean smoothness</th>\n",
              "      <th>mean compactness</th>\n",
              "      <th>mean concavity</th>\n",
              "      <th>mean concave points</th>\n",
              "      <th>mean symmetry</th>\n",
              "      <th>mean fractal dimension</th>\n",
              "      <th>radius error</th>\n",
              "      <th>texture error</th>\n",
              "      <th>perimeter error</th>\n",
              "      <th>area error</th>\n",
              "      <th>smoothness error</th>\n",
              "      <th>compactness error</th>\n",
              "      <th>concavity error</th>\n",
              "      <th>concave points error</th>\n",
              "      <th>symmetry error</th>\n",
              "      <th>fractal dimension error</th>\n",
              "      <th>worst radius</th>\n",
              "      <th>worst texture</th>\n",
              "      <th>worst perimeter</th>\n",
              "      <th>worst area</th>\n",
              "      <th>worst smoothness</th>\n",
              "      <th>worst compactness</th>\n",
              "      <th>worst concavity</th>\n",
              "      <th>worst concave points</th>\n",
              "      <th>worst symmetry</th>\n",
              "      <th>worst fractal dimension</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>17.99</td>\n",
              "      <td>10.38</td>\n",
              "      <td>122.80</td>\n",
              "      <td>1001.0</td>\n",
              "      <td>0.11840</td>\n",
              "      <td>0.27760</td>\n",
              "      <td>0.30010</td>\n",
              "      <td>0.14710</td>\n",
              "      <td>0.2419</td>\n",
              "      <td>0.07871</td>\n",
              "      <td>1.0950</td>\n",
              "      <td>0.9053</td>\n",
              "      <td>8.589</td>\n",
              "      <td>153.40</td>\n",
              "      <td>0.006399</td>\n",
              "      <td>0.04904</td>\n",
              "      <td>0.05373</td>\n",
              "      <td>0.01587</td>\n",
              "      <td>0.03003</td>\n",
              "      <td>0.006193</td>\n",
              "      <td>25.380</td>\n",
              "      <td>17.33</td>\n",
              "      <td>184.60</td>\n",
              "      <td>2019.0</td>\n",
              "      <td>0.16220</td>\n",
              "      <td>0.66560</td>\n",
              "      <td>0.7119</td>\n",
              "      <td>0.2654</td>\n",
              "      <td>0.4601</td>\n",
              "      <td>0.11890</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>20.57</td>\n",
              "      <td>17.77</td>\n",
              "      <td>132.90</td>\n",
              "      <td>1326.0</td>\n",
              "      <td>0.08474</td>\n",
              "      <td>0.07864</td>\n",
              "      <td>0.08690</td>\n",
              "      <td>0.07017</td>\n",
              "      <td>0.1812</td>\n",
              "      <td>0.05667</td>\n",
              "      <td>0.5435</td>\n",
              "      <td>0.7339</td>\n",
              "      <td>3.398</td>\n",
              "      <td>74.08</td>\n",
              "      <td>0.005225</td>\n",
              "      <td>0.01308</td>\n",
              "      <td>0.01860</td>\n",
              "      <td>0.01340</td>\n",
              "      <td>0.01389</td>\n",
              "      <td>0.003532</td>\n",
              "      <td>24.990</td>\n",
              "      <td>23.41</td>\n",
              "      <td>158.80</td>\n",
              "      <td>1956.0</td>\n",
              "      <td>0.12380</td>\n",
              "      <td>0.18660</td>\n",
              "      <td>0.2416</td>\n",
              "      <td>0.1860</td>\n",
              "      <td>0.2750</td>\n",
              "      <td>0.08902</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>19.69</td>\n",
              "      <td>21.25</td>\n",
              "      <td>130.00</td>\n",
              "      <td>1203.0</td>\n",
              "      <td>0.10960</td>\n",
              "      <td>0.15990</td>\n",
              "      <td>0.19740</td>\n",
              "      <td>0.12790</td>\n",
              "      <td>0.2069</td>\n",
              "      <td>0.05999</td>\n",
              "      <td>0.7456</td>\n",
              "      <td>0.7869</td>\n",
              "      <td>4.585</td>\n",
              "      <td>94.03</td>\n",
              "      <td>0.006150</td>\n",
              "      <td>0.04006</td>\n",
              "      <td>0.03832</td>\n",
              "      <td>0.02058</td>\n",
              "      <td>0.02250</td>\n",
              "      <td>0.004571</td>\n",
              "      <td>23.570</td>\n",
              "      <td>25.53</td>\n",
              "      <td>152.50</td>\n",
              "      <td>1709.0</td>\n",
              "      <td>0.14440</td>\n",
              "      <td>0.42450</td>\n",
              "      <td>0.4504</td>\n",
              "      <td>0.2430</td>\n",
              "      <td>0.3613</td>\n",
              "      <td>0.08758</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>11.42</td>\n",
              "      <td>20.38</td>\n",
              "      <td>77.58</td>\n",
              "      <td>386.1</td>\n",
              "      <td>0.14250</td>\n",
              "      <td>0.28390</td>\n",
              "      <td>0.24140</td>\n",
              "      <td>0.10520</td>\n",
              "      <td>0.2597</td>\n",
              "      <td>0.09744</td>\n",
              "      <td>0.4956</td>\n",
              "      <td>1.1560</td>\n",
              "      <td>3.445</td>\n",
              "      <td>27.23</td>\n",
              "      <td>0.009110</td>\n",
              "      <td>0.07458</td>\n",
              "      <td>0.05661</td>\n",
              "      <td>0.01867</td>\n",
              "      <td>0.05963</td>\n",
              "      <td>0.009208</td>\n",
              "      <td>14.910</td>\n",
              "      <td>26.50</td>\n",
              "      <td>98.87</td>\n",
              "      <td>567.7</td>\n",
              "      <td>0.20980</td>\n",
              "      <td>0.86630</td>\n",
              "      <td>0.6869</td>\n",
              "      <td>0.2575</td>\n",
              "      <td>0.6638</td>\n",
              "      <td>0.17300</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>20.29</td>\n",
              "      <td>14.34</td>\n",
              "      <td>135.10</td>\n",
              "      <td>1297.0</td>\n",
              "      <td>0.10030</td>\n",
              "      <td>0.13280</td>\n",
              "      <td>0.19800</td>\n",
              "      <td>0.10430</td>\n",
              "      <td>0.1809</td>\n",
              "      <td>0.05883</td>\n",
              "      <td>0.7572</td>\n",
              "      <td>0.7813</td>\n",
              "      <td>5.438</td>\n",
              "      <td>94.44</td>\n",
              "      <td>0.011490</td>\n",
              "      <td>0.02461</td>\n",
              "      <td>0.05688</td>\n",
              "      <td>0.01885</td>\n",
              "      <td>0.01756</td>\n",
              "      <td>0.005115</td>\n",
              "      <td>22.540</td>\n",
              "      <td>16.67</td>\n",
              "      <td>152.20</td>\n",
              "      <td>1575.0</td>\n",
              "      <td>0.13740</td>\n",
              "      <td>0.20500</td>\n",
              "      <td>0.4000</td>\n",
              "      <td>0.1625</td>\n",
              "      <td>0.2364</td>\n",
              "      <td>0.07678</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>21.56</td>\n",
              "      <td>22.39</td>\n",
              "      <td>142.00</td>\n",
              "      <td>1479.0</td>\n",
              "      <td>0.11100</td>\n",
              "      <td>0.11590</td>\n",
              "      <td>0.24390</td>\n",
              "      <td>0.13890</td>\n",
              "      <td>0.1726</td>\n",
              "      <td>0.05623</td>\n",
              "      <td>1.1760</td>\n",
              "      <td>1.2560</td>\n",
              "      <td>7.673</td>\n",
              "      <td>158.70</td>\n",
              "      <td>0.010300</td>\n",
              "      <td>0.02891</td>\n",
              "      <td>0.05198</td>\n",
              "      <td>0.02454</td>\n",
              "      <td>0.01114</td>\n",
              "      <td>0.004239</td>\n",
              "      <td>25.450</td>\n",
              "      <td>26.40</td>\n",
              "      <td>166.10</td>\n",
              "      <td>2027.0</td>\n",
              "      <td>0.14100</td>\n",
              "      <td>0.21130</td>\n",
              "      <td>0.4107</td>\n",
              "      <td>0.2216</td>\n",
              "      <td>0.2060</td>\n",
              "      <td>0.07115</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>20.13</td>\n",
              "      <td>28.25</td>\n",
              "      <td>131.20</td>\n",
              "      <td>1261.0</td>\n",
              "      <td>0.09780</td>\n",
              "      <td>0.10340</td>\n",
              "      <td>0.14400</td>\n",
              "      <td>0.09791</td>\n",
              "      <td>0.1752</td>\n",
              "      <td>0.05533</td>\n",
              "      <td>0.7655</td>\n",
              "      <td>2.4630</td>\n",
              "      <td>5.203</td>\n",
              "      <td>99.04</td>\n",
              "      <td>0.005769</td>\n",
              "      <td>0.02423</td>\n",
              "      <td>0.03950</td>\n",
              "      <td>0.01678</td>\n",
              "      <td>0.01898</td>\n",
              "      <td>0.002498</td>\n",
              "      <td>23.690</td>\n",
              "      <td>38.25</td>\n",
              "      <td>155.00</td>\n",
              "      <td>1731.0</td>\n",
              "      <td>0.11660</td>\n",
              "      <td>0.19220</td>\n",
              "      <td>0.3215</td>\n",
              "      <td>0.1628</td>\n",
              "      <td>0.2572</td>\n",
              "      <td>0.06637</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>16.60</td>\n",
              "      <td>28.08</td>\n",
              "      <td>108.30</td>\n",
              "      <td>858.1</td>\n",
              "      <td>0.08455</td>\n",
              "      <td>0.10230</td>\n",
              "      <td>0.09251</td>\n",
              "      <td>0.05302</td>\n",
              "      <td>0.1590</td>\n",
              "      <td>0.05648</td>\n",
              "      <td>0.4564</td>\n",
              "      <td>1.0750</td>\n",
              "      <td>3.425</td>\n",
              "      <td>48.55</td>\n",
              "      <td>0.005903</td>\n",
              "      <td>0.03731</td>\n",
              "      <td>0.04730</td>\n",
              "      <td>0.01557</td>\n",
              "      <td>0.01318</td>\n",
              "      <td>0.003892</td>\n",
              "      <td>18.980</td>\n",
              "      <td>34.12</td>\n",
              "      <td>126.70</td>\n",
              "      <td>1124.0</td>\n",
              "      <td>0.11390</td>\n",
              "      <td>0.30940</td>\n",
              "      <td>0.3403</td>\n",
              "      <td>0.1418</td>\n",
              "      <td>0.2218</td>\n",
              "      <td>0.07820</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>20.60</td>\n",
              "      <td>29.33</td>\n",
              "      <td>140.10</td>\n",
              "      <td>1265.0</td>\n",
              "      <td>0.11780</td>\n",
              "      <td>0.27700</td>\n",
              "      <td>0.35140</td>\n",
              "      <td>0.15200</td>\n",
              "      <td>0.2397</td>\n",
              "      <td>0.07016</td>\n",
              "      <td>0.7260</td>\n",
              "      <td>1.5950</td>\n",
              "      <td>5.772</td>\n",
              "      <td>86.22</td>\n",
              "      <td>0.006522</td>\n",
              "      <td>0.06158</td>\n",
              "      <td>0.07117</td>\n",
              "      <td>0.01664</td>\n",
              "      <td>0.02324</td>\n",
              "      <td>0.006185</td>\n",
              "      <td>25.740</td>\n",
              "      <td>39.42</td>\n",
              "      <td>184.60</td>\n",
              "      <td>1821.0</td>\n",
              "      <td>0.16500</td>\n",
              "      <td>0.86810</td>\n",
              "      <td>0.9387</td>\n",
              "      <td>0.2650</td>\n",
              "      <td>0.4087</td>\n",
              "      <td>0.12400</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>7.76</td>\n",
              "      <td>24.54</td>\n",
              "      <td>47.92</td>\n",
              "      <td>181.0</td>\n",
              "      <td>0.05263</td>\n",
              "      <td>0.04362</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.1587</td>\n",
              "      <td>0.05884</td>\n",
              "      <td>0.3857</td>\n",
              "      <td>1.4280</td>\n",
              "      <td>2.548</td>\n",
              "      <td>19.15</td>\n",
              "      <td>0.007189</td>\n",
              "      <td>0.00466</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.02676</td>\n",
              "      <td>0.002783</td>\n",
              "      <td>9.456</td>\n",
              "      <td>30.37</td>\n",
              "      <td>59.16</td>\n",
              "      <td>268.6</td>\n",
              "      <td>0.08996</td>\n",
              "      <td>0.06444</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.0000</td>\n",
              "      <td>0.2871</td>\n",
              "      <td>0.07039</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>569 rows × 31 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     mean radius  mean texture  ...  worst fractal dimension  target\n",
              "0          17.99         10.38  ...                  0.11890     0.0\n",
              "1          20.57         17.77  ...                  0.08902     0.0\n",
              "2          19.69         21.25  ...                  0.08758     0.0\n",
              "3          11.42         20.38  ...                  0.17300     0.0\n",
              "4          20.29         14.34  ...                  0.07678     0.0\n",
              "..           ...           ...  ...                      ...     ...\n",
              "564        21.56         22.39  ...                  0.07115     0.0\n",
              "565        20.13         28.25  ...                  0.06637     0.0\n",
              "566        16.60         28.08  ...                  0.07820     0.0\n",
              "567        20.60         29.33  ...                  0.12400     0.0\n",
              "568         7.76         24.54  ...                  0.07039     1.0\n",
              "\n",
              "[569 rows x 31 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H821OO8t8bmU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 425
        },
        "outputId": "d55646a4-74e9-47a6-d8a5-4f37b6c91f30"
      },
      "source": [
        "# From: https://elitedatascience.com/imbalanced-classes\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        " \n",
        "# Read dataset\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/ivonnics/Machine-Learning/master/DATA/balance-scale.data', \n",
        "                 names=['balance', 'var1', 'var2', 'var3', 'var4'])\n",
        " \n",
        "# Display example observations\n",
        "print(df.info())\n",
        "df.head()"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 625 entries, 0 to 624\n",
            "Data columns (total 5 columns):\n",
            " #   Column   Non-Null Count  Dtype \n",
            "---  ------   --------------  ----- \n",
            " 0   balance  625 non-null    object\n",
            " 1   var1     625 non-null    int64 \n",
            " 2   var2     625 non-null    int64 \n",
            " 3   var3     625 non-null    int64 \n",
            " 4   var4     625 non-null    int64 \n",
            "dtypes: int64(4), object(1)\n",
            "memory usage: 24.5+ KB\n",
            "None\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>balance</th>\n",
              "      <th>var1</th>\n",
              "      <th>var2</th>\n",
              "      <th>var3</th>\n",
              "      <th>var4</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>B</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>R</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>R</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>R</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>R</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "  balance  var1  var2  var3  var4\n",
              "0       B     1     1     1     1\n",
              "1       R     1     1     1     2\n",
              "2       R     1     1     1     3\n",
              "3       R     1     1     1     4\n",
              "4       R     1     1     1     5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JWXoT7749G8h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "85017be2-794b-4c7a-d5a0-22de1b322a70"
      },
      "source": [
        "print(df['balance'].value_counts())\n",
        "print(df['var1'].value_counts())\n",
        "print(df['var2'].value_counts())\n",
        "print(df['var3'].value_counts())\n",
        "print(df['var4'].value_counts())"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "R    288\n",
            "L    288\n",
            "B     49\n",
            "Name: balance, dtype: int64\n",
            "5    125\n",
            "4    125\n",
            "3    125\n",
            "2    125\n",
            "1    125\n",
            "Name: var1, dtype: int64\n",
            "5    125\n",
            "4    125\n",
            "3    125\n",
            "2    125\n",
            "1    125\n",
            "Name: var2, dtype: int64\n",
            "5    125\n",
            "4    125\n",
            "3    125\n",
            "2    125\n",
            "1    125\n",
            "Name: var3, dtype: int64\n",
            "5    125\n",
            "4    125\n",
            "3    125\n",
            "2    125\n",
            "1    125\n",
            "Name: var4, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GwUjg7uF9j0I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "ecf84781-ee11-4eb7-b776-9d572dc0a37d"
      },
      "source": [
        "df['balance'] = [1 if b=='B' else 0 for b in df.balance]\n",
        "df['balance'].value_counts()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    576\n",
              "1     49\n",
              "Name: balance, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wpDpcF0_-_Nk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G2rWG-AM_CuQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f4e939f0-f51f-48e5-9b35-d8087f7e40ea"
      },
      "source": [
        "# Separate input features (X) and target variable (y)\n",
        "y = df.balance\n",
        "X = df.drop('balance', axis=1)\n",
        " \n",
        "# Train model\n",
        "clf_0 = LogisticRegression().fit(X, y)\n",
        " \n",
        "# Predict on training set\n",
        "pred_y_0 = clf_0.predict(X)\n",
        "# How's the accuracy?\n",
        "print( accuracy_score(pred_y_0, y) )"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.9216\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ciMQ5bkz_Zi-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a34f905b-2432-4a2d-e278-5ce7c4483afc"
      },
      "source": [
        "# Should we be excited?\n",
        "print( np.unique( pred_y_0 ) )"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FehKJm3_6G9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.utils import resample"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCM3awkoAA68",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "c1b941b3-cf45-45f1-a690-bc3736f44cc8"
      },
      "source": [
        "# Separate majority and minority classes\n",
        "df_majority = df[df.balance==0]\n",
        "df_minority = df[df.balance==1]\n",
        " \n",
        "# Upsample minority class\n",
        "df_minority_upsampled = resample(df_minority, \n",
        "                                 replace=True,     # sample with replacement\n",
        "                                 n_samples=576,    # to match majority class\n",
        "                                 random_state=123) # reproducible results\n",
        " \n",
        "# Combine majority class with upsampled minority class\n",
        "df_upsampled = pd.concat([df_majority, df_minority_upsampled])\n",
        " \n",
        "# Display new class counts\n",
        "df_upsampled.balance.value_counts()"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    576\n",
              "0    576\n",
              "Name: balance, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPDJboG5AGfr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "ec504bdb-9862-4e8e-f5e9-ab4b2e11a164"
      },
      "source": [
        "# Separate input features (X) and target variable (y)\n",
        "y = df_upsampled.balance\n",
        "X = df_upsampled.drop('balance', axis=1)\n",
        " \n",
        "# Train model\n",
        "clf_1 = LogisticRegression().fit(X, y)\n",
        " \n",
        "# Predict on training set\n",
        "pred_y_1 = clf_1.predict(X)\n",
        " \n",
        "# Is our model still predicting just one class?\n",
        "print( np.unique( pred_y_1 ) )\n",
        "# [0 1]\n",
        " \n",
        "# How's our accuracy?\n",
        "print( accuracy_score(y, pred_y_1) )\n",
        "# 0.513888888889"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1]\n",
            "0.5147569444444444\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxZrhKH-AOap",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "73256ae2-44e3-4631-ff18-867d0d4a34f3"
      },
      "source": [
        "# Separate majority and minority classes\n",
        "df_majority = df[df.balance==0]\n",
        "df_minority = df[df.balance==1]\n",
        " \n",
        "# Downsample majority class\n",
        "df_majority_downsampled = resample(df_majority, \n",
        "                                 replace=False,    # sample without replacement\n",
        "                                 n_samples=49,     # to match minority class\n",
        "                                 random_state=123) # reproducible results\n",
        " \n",
        "# Combine minority class with downsampled majority class\n",
        "df_downsampled = pd.concat([df_majority_downsampled, df_minority])\n",
        " \n",
        "# Display new class counts\n",
        "df_downsampled.balance.value_counts()"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    49\n",
              "0    49\n",
              "Name: balance, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "boNeLM1sATgE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "a6c67dea-0186-44cb-810c-090c280fcca5"
      },
      "source": [
        "\n",
        "3\n",
        "4\n",
        "5\n",
        "6\n",
        "7\n",
        "8\n",
        "9\n",
        "10\n",
        "11\n",
        "12\n",
        "13\n",
        "14\n",
        "15\n",
        "16\n",
        "17\n",
        "# Separate input features (X) and target variable (y)\n",
        "y = df_downsampled.balance\n",
        "X = df_downsampled.drop('balance', axis=1)\n",
        " \n",
        "# Train model\n",
        "clf_2 = LogisticRegression().fit(X, y)\n",
        " \n",
        "# Predict on training set\n",
        "pred_y_2 = clf_2.predict(X)\n",
        " \n",
        "# Is our model still predicting just one class?\n",
        "print( np.unique( pred_y_2 ) )\n",
        "# [0 1]\n",
        " \n",
        "# How's our accuracy?\n",
        "print( accuracy_score(y, pred_y_2) )\n",
        "# 0.581632653061"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1]\n",
            "0.5612244897959183\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uOujHr7cCgCQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MIoafL9gCklU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "a28d3b54-c542-4461-9ea5-9b754a03a2b6"
      },
      "source": [
        "# Predict class probabilities\n",
        "prob_y_2 = clf_2.predict_proba(X)\n",
        " \n",
        "# Keep only the positive class\n",
        "prob_y_2 = [p[1] for p in prob_y_2]\n",
        " \n",
        "prob_y_2[:5] # Example\n",
        "# [0.45419197226479618,\n",
        "#  0.48205962213283882,\n",
        "#  0.46862327066392456,\n",
        "#  0.47868378832689096,\n",
        "#  0.58143856820159667]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.45153197257586,\n",
              " 0.48726124480998256,\n",
              " 0.47238960854127193,\n",
              " 0.47014610622647623,\n",
              " 0.587660295588417]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "liCH3GQkDkK5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "915e0c0e-d799-4166-c0af-97892bf64bbc"
      },
      "source": [
        "print( roc_auc_score(y, prob_y_2) )\n",
        "# 0.568096626406"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.5651811745106206\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7xDgxGj3Dpxu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9b501046-4247-4622-f548-4b616009cff2"
      },
      "source": [
        "prob_y_0 = clf_0.predict_proba(X)\n",
        "prob_y_0 = [p[1] for p in prob_y_0]\n",
        " \n",
        "print( roc_auc_score(y, prob_y_0) )\n",
        "# 0.530718537415"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.4735526863806747\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Svt2rLfVDygB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\tfrom sklearn.svm import SVC"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mdceHRxVD5ZU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "e4abaea4-a345-4bcc-8a68-aa29c7578deb"
      },
      "source": [
        "\n",
        "1\n",
        "2\n",
        "3\n",
        "4\n",
        "5\n",
        "6\n",
        "7\n",
        "8\n",
        "9\n",
        "10\n",
        "11\n",
        "12\n",
        "13\n",
        "14\n",
        "15\n",
        "16\n",
        "17\n",
        "18\n",
        "19\n",
        "20\n",
        "21\n",
        "22\n",
        "23\n",
        "24\n",
        "25\n",
        "26\n",
        "27\n",
        "# Separate input features (X) and target variable (y)\n",
        "y = df.balance\n",
        "X = df.drop('balance', axis=1)\n",
        " \n",
        "# Train model\n",
        "clf_3 = SVC(kernel='linear', \n",
        "            class_weight='balanced', # penalize\n",
        "            probability=True)\n",
        " \n",
        "clf_3.fit(X, y)\n",
        " \n",
        "# Predict on training set\n",
        "pred_y_3 = clf_3.predict(X)\n",
        " \n",
        "# Is our model still predicting just one class?\n",
        "print( np.unique( pred_y_3 ) )\n",
        "# [0 1]\n",
        " \n",
        "# How's our accuracy?\n",
        "print( accuracy_score(y, pred_y_3) )\n",
        "# 0.688\n",
        " \n",
        "# What about AUROC?\n",
        "prob_y_3 = clf_3.predict_proba(X)\n",
        "prob_y_3 = [p[1] for p in prob_y_3]\n",
        "print( roc_auc_score(y, prob_y_3) )\n",
        "# 0.5305236678"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1]\n",
            "0.688\n",
            "0.46947633219954643\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SU_5rPw0EBlM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.ensemble import RandomForestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QEhgAGgEGx9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "7ce9a461-94ab-4125-ab3f-c29a1e0915f8"
      },
      "source": [
        "# Separate input features (X) and target variable (y)\n",
        "y = df.balance\n",
        "X = df.drop('balance', axis=1)\n",
        " \n",
        "# Train model\n",
        "clf_4 = RandomForestClassifier()\n",
        "clf_4.fit(X, y)\n",
        " \n",
        "# Predict on training set\n",
        "pred_y_4 = clf_4.predict(X)\n",
        " \n",
        "# Is our model still predicting just one class?\n",
        "print( np.unique( pred_y_4 ) )\n",
        "# [0 1]\n",
        " \n",
        "# How's our accuracy?\n",
        "print( accuracy_score(y, pred_y_4) )\n",
        "# 0.9744\n",
        " \n",
        "# What about AUROC?\n",
        "prob_y_4 = clf_4.predict_proba(X)\n",
        "prob_y_4 = [p[1] for p in prob_y_4]\n",
        "print( roc_auc_score(y, prob_y_4) )\n",
        "# 0.999078798186"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 1]\n",
            "1.0\n",
            "1.0\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}