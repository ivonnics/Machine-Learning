{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "MLP CREDITCARD Analysis.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ivonnics/Machine-Learning/blob/master/MLP_CREDITCARD_Analysis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_LemWlojns9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# main libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import time\n",
        "# visual libraries\n",
        "from matplotlib import pyplot as plt\n",
        "import seaborn as sns\n",
        "from mpl_toolkits.mplot3d import Axes3D \n",
        "plt.style.use('ggplot')\n",
        "# sklearn libraries\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import normalize\n",
        "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score,recall_score,f1_score,matthews_corrcoef,classification_report,roc_curve\n",
        "from sklearn.externals import joblib\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlZuy5DqjsZu",
        "colab_type": "text"
      },
      "source": [
        "# Tomado de: https://towardsdatascience.com/data-pre-processing-techniques-you-should-know-8954662716d6"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83lwvpkujx_a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Read the data in the CSV file using pandas\n",
        "df = pd.read_csv('https://raw.githubusercontent.com/nsethi31/Kaggle-Data-Credit-Card-Fraud-Detection/master/creditcard.csv')\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IpnSWHhXkI6J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df.isnull().any().sum()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fXKrxKgmkNJI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "All = df.shape[0]\n",
        "fraud = df[df['Class'] == 1]\n",
        "nonFraud = df[df['Class'] == 0]\n",
        "\n",
        "x = len(fraud)/All\n",
        "y = len(nonFraud)/All\n",
        "\n",
        "print('frauds :',x*100,'%')\n",
        "print('non frauds :',y*100,'%')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I02XwpZ7kR3A",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Let's plot the Transaction class against the Frequency\n",
        "labels = ['non frauds','fraud']\n",
        "classes = pd.value_counts(df['Class'], sort = True)\n",
        "classes.plot(kind = 'bar', rot=0)\n",
        "plt.title(\"Transaction class distribution\")\n",
        "plt.xticks(range(2), labels)\n",
        "plt.xlabel(\"Class\")\n",
        "plt.ylabel(\"Frequency\")\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JHdB-_UskWFI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# distribution of Amount\n",
        "amount = [df['Amount'].values]\n",
        "sns.distplot(amount)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5XsXueAkZuA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# distribution of Time\n",
        "time = df['Time'].values\n",
        "sns.distplot(time)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z6kSomN6kdl7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# distribution of anomalous features\n",
        "import matplotlib.gridspec as gridspec\n",
        "anomalous_features = df.iloc[:,1:29].columns\n",
        "print(anomalous_features)\n",
        "\n",
        "anomalous_features2 = df.iloc[:,1:29]\n",
        "print(anomalous_features2.shape)\n",
        "print(anomalous_features2.head())\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lZEqdS2w0qXX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# heat map of correlation of features\n",
        "correlation_matrix = anomalous_features2.corr()\n",
        "fig = plt.figure(figsize=(12,9))\n",
        "sns.heatmap(correlation_matrix,vmax=0.8,square = True)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CQhG3U0730Zu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.cluster import KMeans\n",
        "\n",
        "# build the clustering model\n",
        "kmeans = KMeans(n_clusters=3)\n",
        "kmeans.fit(anomalous_features2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EsEh0hHo4KX6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(\"Cluster memberships:\\n{}\".format(kmeans.labels_[0:28]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ud1Dxt6b4UVd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(kmeans.predict(anomalous_features2[0:28]))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J3QrSCnV-x5f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "km = KMeans(n_clusters=3, \n",
        "            init= 'k-means++', \n",
        "            n_init=20, \n",
        "            max_iter=2000,\n",
        "            tol=1e-03,\n",
        "            random_state=0)\n",
        "y_km = km.fit_predict(anomalous_features2)\n",
        "print(y_km[0:28] )\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WkesN5DfW7xu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Standardizing the features\n",
        "df['Vamount'] = StandardScaler().fit_transform(df['Amount'].values.reshape(-1,1))\n",
        "df['Vtime'] = StandardScaler().fit_transform(df['Time'].values.reshape(-1,1))\n",
        "\n",
        "df = df.drop(['Time','Amount'], axis = 1)\n",
        "print(df.shape)\n",
        "df.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qun3nQNtZ9WA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#! pip install mglearn"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2FiUYrtqaH88",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#import mglearn\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "\n",
        "from sklearn.datasets import make_moons\n",
        "\n",
        "X = df.drop(['Class'], axis = 1)\n",
        "y = df['Class']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y,test_size=0.05,\n",
        "                                                    random_state=42)\n",
        "\n",
        "mlp = MLPClassifier(solver='lbfgs', random_state=0).fit(X_train, y_train)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TFDspPXAev0E",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        " Testing= mlp.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kmd0orrHfH12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix\n",
        "confmat = confusion_matrix(y_true=y_test, y_pred=Testing)\n",
        "print(confmat)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2V4YIu_0feBT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fig, ax = plt.subplots(figsize=(2.5, 2.5))\n",
        "ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
        "for i in range(confmat.shape[0]):\n",
        "    for j in range(confmat.shape[1]):\n",
        "        ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
        "\n",
        "plt.xlabel('predicted label')\n",
        "plt.ylabel('true label')\n",
        "\n",
        "plt.tight_layout()\n",
        "# plt.savefig('./figures/confusion_matrix.png', dpi=300)\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GEtoefCogfs3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import classification_report\n",
        "y_pred = Testing\n",
        "y_true = y_test\n",
        "print('accuracy_score = ',accuracy_score(y_true, y_pred)*100,'%')\n",
        "print('Total accurate predictions = ',accuracy_score(y_true, y_pred, normalize=False))\n",
        "target_names = ['class 0', 'class 1']\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yw4RnfFOkaDU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp = MLPClassifier(solver='lbfgs', random_state=0, activation='tanh',hidden_layer_sizes=[10])\n",
        "mlp.fit(X_train, y_train)\n",
        "Testing= mlp.predict(X_test)\n",
        "confmat = confusion_matrix(y_true=y_test, y_pred=Testing)\n",
        "print(confmat)\n",
        "fig, ax = plt.subplots(figsize=(2.5, 2.5))\n",
        "ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
        "for i in range(confmat.shape[0]):\n",
        "    for j in range(confmat.shape[1]):\n",
        "        ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
        "\n",
        "plt.xlabel('predicted label')\n",
        "plt.ylabel('true label')\n",
        "\n",
        "plt.tight_layout()\n",
        "# plt.savefig('./figures/confusion_matrix.png', dpi=300)\n",
        "plt.show()\n",
        "y_pred = Testing\n",
        "y_true = y_test\n",
        "print('accuracy_score = ',accuracy_score(y_true, y_pred)*100,'%')\n",
        "print('Total accurate predictions = ',accuracy_score(y_true, y_pred, normalize=False))\n",
        "target_names = ['class 0', 'class 1']\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gjWEQKWsLgdW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "mlp = MLPClassifier(solver='adam',activation= 'tanh', alpha= 0.0001,hidden_layer_sizes= (100,),learning_rate= 'adaptive',random_state=0)\n",
        "mlp.fit(X_train, y_train)\n",
        "Testing= mlp.predict(X_test)\n",
        "confmat = confusion_matrix(y_true=y_test, y_pred=Testing)\n",
        "print(confmat)\n",
        "fig, ax = plt.subplots(figsize=(2.5, 2.5))\n",
        "ax.matshow(confmat, cmap=plt.cm.Blues, alpha=0.3)\n",
        "for i in range(confmat.shape[0]):\n",
        "    for j in range(confmat.shape[1]):\n",
        "        ax.text(x=j, y=i, s=confmat[i, j], va='center', ha='center')\n",
        "\n",
        "plt.xlabel('predicted label')\n",
        "plt.ylabel('true label')\n",
        "\n",
        "plt.tight_layout()\n",
        "# plt.savefig('./figures/confusion_matrix.png', dpi=300)\n",
        "plt.show()\n",
        "y_pred = Testing\n",
        "y_true = y_test\n",
        "print('accuracy_score = ',accuracy_score(y_true, y_pred)*100,'%')\n",
        "print('Total accurate predictions = ',accuracy_score(y_true, y_pred, normalize=False))\n",
        "target_names = ['class 0', 'class 1']\n",
        "print(classification_report(y_true, y_pred, target_names=target_names))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "m9SarEhtMupl",
        "colab_type": "text"
      },
      "source": [
        "## Metrics used to evaluate models in Scikit learn: \n",
        "https://towardsdatascience.com/understanding-data-science-classification-metrics-in-scikit-learn-in-python-3bc336865019\n",
        "\n",
        "accuracy_score:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dgVxRpE2M8TM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "accuracy_score(y_true, y_pred)\n",
        "# Accuracy is the fraction of samples predicted correctly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n9Ix3PbDPQwU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import recall_score\n",
        "recall_score(y_true, y_pred)\n",
        "# Recall (also known as sensitivity) is the fraction of positives events that were predicted correctly"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M12ryExHPjhV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import precision_score\n",
        "precision_score(y_true, y_pred)\n",
        "# Precision is the fraction of predicted positives events that are actually positive "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xmoLr1EBP0H0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "f1_score(y_true, y_pred)\n",
        "# The f1 score is the harmonic mean of recall and precision, with a higher score as a better model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ofgz_8kbP8NM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_curve\n",
        "fpr_RF, tpr_RF, thresholds_RF = roc_curve(y_true, y_pred)\n",
        "# ROC curves are VERY help with understanding the balance between true-positive\n",
        "# rate and false positive rates. Sci-kit learn has built in functions for ROC curves\n",
        "# and for analyzing them. The inputs to these functions (roc_curve and roc_auc_score)\n",
        "# are the actual labels and the predicted probabilities (not the predicted labels).\n",
        "# Both roc_curve and roc_auc_score are both complicated functions, they are used\n",
        "# TO COMPARE MODELS` PERFORMANcE (see article)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_Fzvs1VQKKL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "thresholds_RF"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n5W7jKvJQSas",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "fpr_RF"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T16_V_19QWUw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tpr_RF"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CWPmEJr_QZcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(fpr_RF, tpr_RF,'r-',label = 'RF')\n",
        "plt.plot([0,1],[0,1],'k-',label='random')\n",
        "plt.plot([0,0,1,1],[0,1,1,1],'g-',label='perfect')\n",
        "plt.legend()\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyEYe7UwQoJ4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "auc_RF = roc_auc_score(y_true, y_pred)\n",
        "print('AUC RF:%.3f'% auc_RF)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZcpWhSPQ08e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "plt.plot(fpr_RF, tpr_RF,'r-',label = 'RF AUC: %.3f'%auc_RF)\n",
        "plt.plot([0,1],[0,1],'k-',label='random')\n",
        "plt.plot([0,0,1,1],[0,1,1,1],'g-',label='perfect')\n",
        "plt.legend()\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJyX2SNgXeAD",
        "colab_type": "text"
      },
      "source": [
        "## Adjusting the hyperparameters of MLP classifier to get more perfect performance:\n",
        "\n",
        "https://datascience.stackexchange.com/questions/36049/how-to-adjust-the-hyperparameters-of-mlp-classifier-to-get-more-perfect-performa\n",
        "\n",
        "https://machinelearningmastery.com/how-to-tune-algorithm-parameters-with-scikit-learn/"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sYAS0YGL7QsY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# GridSearch fine tuning tomado de: \n",
        "# https://datascience.stackexchange.com/questions/36049/how-to-adjust-the-hyperparameters-of-mlp-classifier-to-get-more-perfect-performa\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "mlp = MLPClassifier(max_iter=100)\n",
        "parameter_space = {\n",
        "    'hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n",
        "    'activation': ['tanh', 'relu'],\n",
        "    'solver': ['sgd', 'adam'],\n",
        "    'alpha': [0.0001, 0.05],\n",
        "    'learning_rate': ['constant','adaptive'],\n",
        "}\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "clf = GridSearchCV(mlp, parameter_space, n_jobs=-1, cv=3)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Best paramete set\n",
        "print('Best parameters found:\\n', clf.best_params_)\n",
        "\n",
        "# All results\n",
        "means = clf.cv_results_['mean_test_score']\n",
        "stds = clf.cv_results_['std_test_score']\n",
        "for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "    print(\"%0.3f (+/-%0.03f) for %r\" % (mean, std * 2, params))\n",
        "\n",
        "y_true, y_pred = y_test , clf.predict(X_test)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print('Results on the test set:')\n",
        "print(classification_report(y_true, y_pred))    "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rwariZgzlrJ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print('accuracy_score = ',accuracy_score(y_true, y_pred)*100,'%')\n",
        "print('Total accurate predictions = ',accuracy_score(y_true, y_pred, normalize=False))\n",
        "target_names = ['class 0', 'class 1']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCwtkgpHe5Lk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import datasets\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import SVC\n",
        "\n",
        "print(__doc__)\n",
        "\n",
        "# Loading the Digits dataset\n",
        "digits = datasets.load_digits()\n",
        "\n",
        "# To apply an classifier on this data, we need to flatten the image, to\n",
        "# turn the data in a (samples, feature) matrix:\n",
        "n_samples = len(digits.images)\n",
        "X = digits.images.reshape((n_samples, -1))\n",
        "y = digits.target\n",
        "\n",
        "# Split the dataset in two equal parts\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.5, random_state=0)\n",
        "\n",
        "# Set the parameters by cross-validation\n",
        "tuned_parameters = [{'kernel': ['rbf'], 'gamma': [1e-3, 1e-4],\n",
        "                     'C': [1, 10, 100, 1000]},\n",
        "                    {'kernel': ['linear'], 'C': [1, 10, 100, 1000]}]\n",
        "\n",
        "scores = ['precision', 'recall']\n",
        "\n",
        "for score in scores:\n",
        "    print(\"# Tuning hyper-parameters for %s\" % score)\n",
        "    print()\n",
        "\n",
        "    clf = GridSearchCV(SVC(), tuned_parameters, cv=5,\n",
        "                       scoring='%s_macro' % score)\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    print(\"Best parameters set found on development set:\")\n",
        "    print()\n",
        "    print(clf.best_params_)\n",
        "    print()\n",
        "    print(\"Grid scores on development set:\")\n",
        "    print()\n",
        "    means = clf.cv_results_['mean_test_score']\n",
        "    stds = clf.cv_results_['std_test_score']\n",
        "    for mean, std, params in zip(means, stds, clf.cv_results_['params']):\n",
        "        print(\"%0.3f (+/-%0.03f) for %r\"\n",
        "              % (mean, std * 2, params))\n",
        "    print()\n",
        "\n",
        "    print(\"Detailed classification report:\")\n",
        "    print()\n",
        "    print(\"The model is trained on the full development set.\")\n",
        "    print(\"The scores are computed on the full evaluation set.\")\n",
        "    print()\n",
        "    y_true, y_pred = y_test, clf.predict(X_test)\n",
        "    print(classification_report(y_true, y_pred))\n",
        "    print()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}